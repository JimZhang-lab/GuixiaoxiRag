#!/usr/bin/env python3
"""
DFAè¿‡æ»¤å™¨æµ‹è¯•è„šæœ¬
"""
import sys
import asyncio
import logging
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from core.dfa_filter import DFAFilter, SensitiveWordManager
from config.settings import Config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_dfa_filter():
    """æµ‹è¯•DFAè¿‡æ»¤å™¨åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•DFAè¿‡æ»¤å™¨åŸºæœ¬åŠŸèƒ½...")
    
    # åˆ›å»ºDFAè¿‡æ»¤å™¨
    dfa = DFAFilter(case_sensitive=False, enable_fuzzy_match=True)
    
    # æ·»åŠ æµ‹è¯•æ•æ„Ÿè¯
    test_words = [
        "æ¯’å“", "æµ·æ´›å› ", "ç‚¸å¼¹", "æªæ”¯", "è¯ˆéª—", "è‰²æƒ…",
        "drugs", "bomb", "fraud", "pornography"
    ]
    
    dfa.add_words(test_words)
    print(f"âœ… æ·»åŠ äº† {len(test_words)} ä¸ªæµ‹è¯•æ•æ„Ÿè¯")
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ", False, "æ­£å¸¸æŸ¥è¯¢"),
        ("å¦‚ä½•åˆ¶ä½œç‚¸å¼¹ï¼Ÿ", True, "åŒ…å«æ•æ„Ÿè¯"),
        ("æ¯’å“çš„å±å®³æœ‰å“ªäº›ï¼Ÿ", True, "åŒ…å«æ•æ„Ÿè¯"),
        ("å¦‚ä½•é˜²èŒƒç½‘ç»œè¯ˆéª—ï¼Ÿ", True, "åŒ…å«æ•æ„Ÿè¯ä½†å¯èƒ½æ˜¯æ•™è‚²æ€§"),
        ("B0MBåˆ¶ä½œæ–¹æ³•", True, "æ¨¡ç³ŠåŒ¹é…æµ‹è¯•"),
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", False, "æ­£å¸¸å†…å®¹")
    ]
    
    print("\nğŸ“ æµ‹è¯•ç”¨ä¾‹:")
    for i, (text, expected, description) in enumerate(test_cases, 1):
        result = dfa.contains_sensitive(text)
        status = "âœ…" if result == expected else "âŒ"
        print(f"   {i}. {description}")
        print(f"      æ–‡æœ¬: {text}")
        print(f"      é¢„æœŸ: {expected}, å®é™…: {result} {status}")
        
        if result:
            sensitive_words = dfa.get_sensitive_words(text)
            filtered_text = dfa.filter_text(text)
            print(f"      æ•æ„Ÿè¯: {sensitive_words}")
            print(f"      è¿‡æ»¤å: {filtered_text}")
        print()
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = dfa.get_stats()
    print(f"ğŸ“Š DFAç»Ÿè®¡ä¿¡æ¯:")
    print(f"   â€¢ æ•æ„Ÿè¯æ•°é‡: {stats['total_words']}")
    print(f"   â€¢ æ ‘èŠ‚ç‚¹æ•°é‡: {stats['tree_nodes']}")
    print(f"   â€¢ åŒºåˆ†å¤§å°å†™: {stats['case_sensitive']}")
    print(f"   â€¢ æ¨¡ç³ŠåŒ¹é…: {stats['fuzzy_match']}")


def test_sensitive_word_manager():
    """æµ‹è¯•æ•æ„Ÿè¯ç®¡ç†å™¨"""
    print("\nğŸ›¡ï¸ æµ‹è¯•æ•æ„Ÿè¯ç®¡ç†å™¨...")
    
    try:
        # åŠ è½½é…ç½®
        config = Config.load_from_yaml()
        
        # åˆ›å»ºæ•æ„Ÿè¯ç®¡ç†å™¨
        manager = SensitiveWordManager(config.safety.model_dump())
        
        # åˆå§‹åŒ–ï¼ˆåŠ è½½æ•æ„Ÿè¯æ–‡ä»¶ï¼‰
        success = manager.initialize()
        if success:
            print("âœ… æ•æ„Ÿè¯ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âš ï¸ æ•æ„Ÿè¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶è·¯å¾„é—®é¢˜")
            return
        
        # æµ‹è¯•å®‰å…¨æ£€æŸ¥
        test_queries = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "å¦‚ä½•åˆ¶ä½œç‚¸å¼¹ï¼Ÿ", 
            "å¦‚ä½•é˜²èŒƒç½‘ç»œè¯ˆéª—ï¼Ÿ",
            "æ¯’å“çš„å±å®³æœ‰å“ªäº›ï¼Ÿ"
        ]
        
        print("\nğŸ“‹ å®‰å…¨æ£€æŸ¥æµ‹è¯•:")
        for i, query in enumerate(test_queries, 1):
            result = manager.check_content_safety(query)
            print(f"   {i}. {query}")
            print(f"      å®‰å…¨: {result['is_safe']}")
            print(f"      çº§åˆ«: {result['safety_level']}")
            print(f"      ç½®ä¿¡åº¦: {result['confidence']}")
            if result['risk_factors']:
                print(f"      é£é™©å› ç´ : {result['risk_factors']}")
            if result.get('sensitive_words'):
                print(f"      æ•æ„Ÿè¯: {result['sensitive_words']}")
            print()
            
    except Exception as e:
        print(f"âŒ æ•æ„Ÿè¯ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")


async def test_query_processor():
    """æµ‹è¯•æŸ¥è¯¢å¤„ç†å™¨é›†æˆ"""
    print("\nğŸ¯ æµ‹è¯•æŸ¥è¯¢å¤„ç†å™¨é›†æˆ...")
    
    try:
        from core.processor import QueryProcessor
        
        # åŠ è½½é…ç½®
        config = Config.load_from_yaml()
        
        # åˆ›å»ºæŸ¥è¯¢å¤„ç†å™¨
        processor = QueryProcessor(config=config)
        
        print("âœ… æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "å¦‚ä½•åˆ¶ä½œç‚¸å¼¹ï¼Ÿ",
            "å¦‚ä½•é˜²èŒƒç½‘ç»œè¯ˆéª—ï¼Ÿ"
        ]
        
        print("\nğŸ” æŸ¥è¯¢å¤„ç†æµ‹è¯•:")
        for i, query in enumerate(test_queries, 1):
            print(f"   {i}. æŸ¥è¯¢: {query}")
            try:
                result = await processor.process_query(query)
                print(f"      æ„å›¾ç±»å‹: {result.intent_type.value}")
                print(f"      å®‰å…¨çº§åˆ«: {result.safety_level.value}")
                print(f"      æ˜¯å¦æ‹’ç»: {result.should_reject}")
                print(f"      ç½®ä¿¡åº¦: {result.confidence:.2f}")
                if result.risk_factors:
                    print(f"      é£é™©å› ç´ : {result.risk_factors}")
                print()
            except Exception as e:
                print(f"      âŒ å¤„ç†å¤±è´¥: {e}")
                print()
                
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")


def test_file_loading():
    """æµ‹è¯•æ–‡ä»¶åŠ è½½åŠŸèƒ½"""
    print("\nğŸ“ æµ‹è¯•æ•æ„Ÿè¯æ–‡ä»¶åŠ è½½...")
    
    # æ£€æŸ¥æ•æ„Ÿè¯ç›®å½•
    vocab_path = Path("../sensitive_vocabulary")
    if vocab_path.exists():
        print(f"âœ… æ‰¾åˆ°æ•æ„Ÿè¯ç›®å½•: {vocab_path.absolute()}")
        
        # åˆ—å‡ºæ–‡ä»¶
        files = list(vocab_path.iterdir())
        print(f"   åŒ…å« {len(files)} ä¸ªæ–‡ä»¶:")
        for file in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"   â€¢ {file.name}")
        if len(files) > 5:
            print(f"   â€¢ ... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶")
        
        # æµ‹è¯•åŠ è½½
        dfa = DFAFilter()
        count = dfa.load_from_directory(str(vocab_path))
        print(f"   æˆåŠŸåŠ è½½ {count} ä¸ªæ•æ„Ÿè¯")
        
    else:
        print(f"âŒ æ•æ„Ÿè¯ç›®å½•ä¸å­˜åœ¨: {vocab_path.absolute()}")
        print("   è¯·ç¡®ä¿æ•æ„Ÿè¯ç›®å½•è·¯å¾„æ­£ç¡®")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª DFAæ•æ„Ÿè¯è¿‡æ»¤å™¨æµ‹è¯•")
    print("=" * 50)
    
    # 1. æµ‹è¯•DFAè¿‡æ»¤å™¨åŸºæœ¬åŠŸèƒ½
    test_dfa_filter()
    
    # 2. æµ‹è¯•æ–‡ä»¶åŠ è½½
    test_file_loading()
    
    # 3. æµ‹è¯•æ•æ„Ÿè¯ç®¡ç†å™¨
    test_sensitive_word_manager()
    
    # 4. æµ‹è¯•æŸ¥è¯¢å¤„ç†å™¨é›†æˆ
    await test_query_processor()
    
    print("=" * 50)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
