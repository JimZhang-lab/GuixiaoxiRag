"""
é›†æˆæµ‹è¯•
æµ‹è¯•å®Œæ•´çš„ä¸šåŠ¡æµç¨‹ï¼ŒéªŒè¯å„ä¸ªæ¨¡å—ä¹‹é—´çš„åä½œ
"""

import pytest
import asyncio
import json
import time
from typing import List, Dict, Any
from pathlib import Path
from conftest import TestClient, TestUtils, API_ENDPOINTS


class TestEndToEndWorkflow:
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_complete_knowledge_management_workflow(self, test_client: TestClient, test_utils: TestUtils, temp_dir: Path):
        """æµ‹è¯•å®Œæ•´çš„çŸ¥è¯†ç®¡ç†å·¥ä½œæµ"""
        
        # 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
        health_response = await test_client.get(API_ENDPOINTS["system"]["health"])
        test_utils.assert_response_success(health_response)
        print("âœ“ ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡")
        
        # 2. åˆ›å»ºæµ‹è¯•çŸ¥è¯†åº“
        kb_name = f"integration_test_kb_{test_utils.generate_test_id()}"
        kb_request = {
            "name": kb_name,
            "description": "é›†æˆæµ‹è¯•çŸ¥è¯†åº“",
            "language": "ä¸­æ–‡",
            "config": {
                "chunk_size": 512,
                "chunk_overlap": 50
            }
        }
        
        kb_response = await test_client.post(API_ENDPOINTS["knowledge_base"]["create"], json_data=kb_request)
        if kb_response.status_code == 200:
            print("âœ“ çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ")
        else:
            print("âš  çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çŸ¥è¯†åº“")
            kb_name = "default"
        
        # 3. åˆ‡æ¢åˆ°æµ‹è¯•çŸ¥è¯†åº“
        if kb_response.status_code == 200:
            switch_request = {"name": kb_name}
            switch_response = await test_client.post(API_ENDPOINTS["knowledge_base"]["switch"], json_data=switch_request)
            if switch_response.status_code == 200:
                print("âœ“ çŸ¥è¯†åº“åˆ‡æ¢æˆåŠŸ")
        
        # 4. æ’å…¥æ–‡æ¡£æ•°æ®
        documents = [
            {
                "text": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚AIæŠ€æœ¯åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªé¢†åŸŸã€‚",
                "doc_id": "ai_intro",
                "knowledge_base": kb_name,
                "language": "ä¸­æ–‡"
            },
            {
                "text": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚æœºå™¨å­¦ä¹ ç®—æ³•åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰å¤§ç±»ã€‚",
                "doc_id": "ml_intro", 
                "knowledge_base": kb_name,
                "language": "ä¸­æ–‡"
            },
            {
                "text": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
                "doc_id": "dl_intro",
                "knowledge_base": kb_name,
                "language": "ä¸­æ–‡"
            }
        ]
        
        for doc in documents:
            doc_response = await test_client.post(API_ENDPOINTS["document"]["insert_text"], json_data=doc)
            test_utils.assert_response_success(doc_response)
        
        print("âœ“ æ–‡æ¡£æ’å…¥å®Œæˆ")
        
        # 5. ç­‰å¾…æ–‡æ¡£å¤„ç†
        await asyncio.sleep(3)
        
        # 6. æ·»åŠ é—®ç­”å¯¹
        qa_pairs = [
            {
                "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                "answer": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
                "category": "AIåŸºç¡€",
                "confidence": 1.0
            },
            {
                "question": "æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ",
                "answer": "æœºå™¨å­¦ä¹ ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰å¤§ç±»ã€‚",
                "category": "æœºå™¨å­¦ä¹ ",
                "confidence": 0.95
            }
        ]
        
        batch_qa_request = {"qa_pairs": qa_pairs}
        qa_response = await test_client.post(API_ENDPOINTS["qa"]["pairs_batch"], json_data=batch_qa_request)
        test_utils.assert_response_success(qa_response)
        print("âœ“ é—®ç­”å¯¹æ·»åŠ å®Œæˆ")
        
        # 7. æ‰§è¡ŒæŸ¥è¯¢æµ‹è¯•
        queries = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "æœºå™¨å­¦ä¹ çš„åˆ†ç±»æœ‰å“ªäº›ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ çš„åº”ç”¨é¢†åŸŸï¼Ÿ"
        ]
        
        for query in queries:
            # æ–‡æ¡£æŸ¥è¯¢
            doc_query_request = {
                "query": query,
                "mode": "hybrid",
                "top_k": 3,
                "knowledge_base": kb_name
            }
            
            doc_query_response = await test_client.post(API_ENDPOINTS["query"]["query"], json_data=doc_query_request)
            test_utils.assert_response_success(doc_query_response)
            
            # é—®ç­”æŸ¥è¯¢
            qa_query_request = {
                "question": query,
                "top_k": 3,
                "min_similarity": 0.7
            }
            
            qa_query_response = await test_client.post(API_ENDPOINTS["qa"]["query"], json_data=qa_query_request)
            test_utils.assert_response_success(qa_query_response)
        
        print("âœ“ æŸ¥è¯¢æµ‹è¯•å®Œæˆ")
        
        # 8. è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
        qa_stats_response = await test_client.get(API_ENDPOINTS["qa"]["statistics"])
        test_utils.assert_response_success(qa_stats_response)
        
        system_metrics_response = await test_client.get(API_ENDPOINTS["system"]["metrics"])
        test_utils.assert_response_success(system_metrics_response)
        
        print("âœ“ ç»Ÿè®¡ä¿¡æ¯è·å–å®Œæˆ")
        
        # 9. æ¸…ç†æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
        if kb_response.status_code == 200:
            # åˆ é™¤æµ‹è¯•çŸ¥è¯†åº“
            delete_response = await test_client.delete(f"/api/v1/knowledge-bases/{kb_name}")
            if delete_response.status_code == 200:
                print("âœ“ æµ‹è¯•çŸ¥è¯†åº“æ¸…ç†å®Œæˆ")
        
        print("ğŸ‰ å®Œæ•´å·¥ä½œæµæµ‹è¯•æˆåŠŸ")
    
    @pytest.mark.asyncio
    async def test_file_upload_to_query_workflow(self, test_client: TestClient, test_utils: TestUtils, temp_dir: Path):
        """æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åˆ°æŸ¥è¯¢çš„å®Œæ•´æµç¨‹"""
        
        # 1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_content = """
# AIæŠ€æœ¯æŒ‡å—

## æ¦‚è¿°
äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸»è¦é¢†åŸŸï¼š

## æœºå™¨å­¦ä¹ 
- ç›‘ç£å­¦ä¹ ï¼šä½¿ç”¨æ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹
- æ— ç›‘ç£å­¦ä¹ ï¼šä»æœªæ ‡è®°æ•°æ®ä¸­å‘ç°æ¨¡å¼
- å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡è¯•é”™å­¦ä¹ æœ€ä¼˜ç­–ç•¥

## æ·±åº¦å­¦ä¹ 
- ç¥ç»ç½‘ç»œï¼šæ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒç»“æ„
- å·ç§¯ç¥ç»ç½‘ç»œï¼šä¸“é—¨ç”¨äºå›¾åƒå¤„ç†
- å¾ªç¯ç¥ç»ç½‘ç»œï¼šå¤„ç†åºåˆ—æ•°æ®

## è‡ªç„¶è¯­è¨€å¤„ç†
- æ–‡æœ¬åˆ†æï¼šç†è§£æ–‡æœ¬å†…å®¹å’Œæƒ…æ„Ÿ
- æœºå™¨ç¿»è¯‘ï¼šè‡ªåŠ¨ç¿»è¯‘ä¸åŒè¯­è¨€
- å¯¹è¯ç³»ç»Ÿï¼šæ„å»ºæ™ºèƒ½èŠå¤©æœºå™¨äºº

## åº”ç”¨åœºæ™¯
1. åŒ»ç–—è¯Šæ–­
2. è‡ªåŠ¨é©¾é©¶
3. é‡‘èé£æ§
4. æ™ºèƒ½æ¨è
        """
        
        test_file = test_utils.create_test_file(test_content, "ai_guide.md", temp_dir)
        
        # 2. ä¸Šä¼ æ–‡ä»¶
        with open(test_file, 'rb') as f:
            files = {"file": ("ai_guide.md", f, "text/markdown")}
            data = {
                "knowledge_base": "test_kb",
                "language": "ä¸­æ–‡",
                "extract_metadata": "true"
            }
            
            upload_response = await test_client.post(API_ENDPOINTS["document"]["insert_file"], data=data, files=files)
            test_utils.assert_response_success(upload_response)
        
        print("âœ“ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")
        
        # 3. ç­‰å¾…æ–‡ä»¶å¤„ç†
        await asyncio.sleep(5)
        
        # 4. æ‰§è¡Œç›¸å…³æŸ¥è¯¢
        queries = [
            "ä»€ä¹ˆæ˜¯ç›‘ç£å­¦ä¹ ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ åŒ…æ‹¬å“ªäº›æŠ€æœ¯ï¼Ÿ",
            "AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ï¼Ÿ",
            "è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸»è¦ä»»åŠ¡ï¼Ÿ"
        ]
        
        successful_queries = 0
        for query in queries:
            query_request = {
                "query": query,
                "mode": "hybrid",
                "top_k": 5
            }
            
            response = await test_client.post(API_ENDPOINTS["query"]["query"], json_data=query_request)
            if response.status_code == 200:
                successful_queries += 1
                data = response.json()
                print(f"âœ“ æŸ¥è¯¢ '{query}' æˆåŠŸ")
        
        assert successful_queries > 0, "æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥äº†"
        print(f"âœ“ {successful_queries}/{len(queries)} ä¸ªæŸ¥è¯¢æˆåŠŸ")
    
    @pytest.mark.asyncio
    async def test_batch_processing_workflow(self, test_client: TestClient, test_utils: TestUtils):
        """æµ‹è¯•æ‰¹é‡å¤„ç†å·¥ä½œæµ"""
        
        # 1. æ‰¹é‡æ’å…¥æ–‡æ¡£
        texts = [
            f"è¿™æ˜¯æµ‹è¯•æ–‡æ¡£{i}ï¼ŒåŒ…å«å…³äºäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å†…å®¹ã€‚" for i in range(10)
        ]
        
        batch_text_request = {
            "texts": texts,
            "doc_ids": [f"batch_doc_{i}" for i in range(10)],
            "knowledge_base": "test_kb",
            "language": "ä¸­æ–‡"
        }
        
        batch_insert_response = await test_client.post(API_ENDPOINTS["document"]["insert_texts"], json_data=batch_text_request)
        test_utils.assert_response_success(batch_insert_response)
        print("âœ“ æ‰¹é‡æ–‡æ¡£æ’å…¥æˆåŠŸ")
        
        # 2. æ‰¹é‡æ·»åŠ é—®ç­”å¯¹
        qa_pairs = [
            {
                "question": f"æ‰¹é‡æµ‹è¯•é—®é¢˜{i}ï¼Ÿ",
                "answer": f"è¿™æ˜¯æ‰¹é‡æµ‹è¯•ç­”æ¡ˆ{i}",
                "category": "æ‰¹é‡æµ‹è¯•",
                "confidence": 0.8
            }
            for i in range(5)
        ]
        
        batch_qa_request = {"qa_pairs": qa_pairs}
        batch_qa_response = await test_client.post(API_ENDPOINTS["qa"]["pairs_batch"], json_data=batch_qa_request)
        test_utils.assert_response_success(batch_qa_response)
        print("âœ“ æ‰¹é‡é—®ç­”å¯¹æ·»åŠ æˆåŠŸ")
        
        # 3. æ‰¹é‡æŸ¥è¯¢
        queries = [f"æ‰¹é‡æµ‹è¯•é—®é¢˜{i}" for i in range(5)]
        
        batch_query_request = {
            "queries": queries,
            "mode": "hybrid",
            "top_k": 3,
            "parallel": True
        }
        
        batch_query_response = await test_client.post(API_ENDPOINTS["query"]["batch"], json_data=batch_query_request)
        test_utils.assert_response_success(batch_query_response)
        print("âœ“ æ‰¹é‡æŸ¥è¯¢æˆåŠŸ")
        
        # 4. æ‰¹é‡é—®ç­”æŸ¥è¯¢
        qa_batch_query_request = {
            "questions": queries,
            "top_k": 3,
            "parallel": True
        }
        
        qa_batch_response = await test_client.post(API_ENDPOINTS["qa"]["query_batch"], json_data=qa_batch_query_request)
        test_utils.assert_response_success(qa_batch_response)
        print("âœ“ æ‰¹é‡é—®ç­”æŸ¥è¯¢æˆåŠŸ")
    
    @pytest.mark.asyncio
    async def test_error_recovery_workflow(self, test_client: TestClient, test_utils: TestUtils):
        """æµ‹è¯•é”™è¯¯æ¢å¤å·¥ä½œæµ"""
        
        # 1. å°è¯•æ— æ•ˆæ“ä½œ
        invalid_requests = [
            # æ— æ•ˆçš„æ–‡æ¡£æ’å…¥
            {
                "endpoint": API_ENDPOINTS["document"]["insert_text"],
                "method": "POST",
                "data": {"text": "", "knowledge_base": "test_kb"}
            },
            # æ— æ•ˆçš„æŸ¥è¯¢
            {
                "endpoint": API_ENDPOINTS["query"]["query"],
                "method": "POST", 
                "data": {"query": "", "mode": "invalid_mode"}
            },
            # æ— æ•ˆçš„é—®ç­”å¯¹
            {
                "endpoint": API_ENDPOINTS["qa"]["pairs"],
                "method": "POST",
                "data": {"question": "", "answer": ""}
            }
        ]
        
        for req in invalid_requests:
            if req["method"] == "POST":
                response = await test_client.post(req["endpoint"], json_data=req["data"])
            else:
                response = await test_client.get(req["endpoint"])
            
            # åº”è¯¥è¿”å›é”™è¯¯ï¼Œä½†ä¸åº”è¯¥å¯¼è‡´ç³»ç»Ÿå´©æºƒ
            assert response.status_code >= 400
        
        print("âœ“ é”™è¯¯å¤„ç†æ­£å¸¸")
        
        # 2. éªŒè¯ç³»ç»Ÿä»ç„¶æ­£å¸¸å·¥ä½œ
        health_response = await test_client.get(API_ENDPOINTS["system"]["health"])
        test_utils.assert_response_success(health_response)
        print("âœ“ ç³»ç»Ÿæ¢å¤æ­£å¸¸")
        
        # 3. æ‰§è¡Œæ­£å¸¸æ“ä½œéªŒè¯åŠŸèƒ½
        valid_doc = {
            "text": "è¿™æ˜¯é”™è¯¯æ¢å¤æµ‹è¯•æ–‡æ¡£",
            "knowledge_base": "test_kb"
        }
        
        doc_response = await test_client.post(API_ENDPOINTS["document"]["insert_text"], json_data=valid_doc)
        test_utils.assert_response_success(doc_response)
        print("âœ“ æ­£å¸¸åŠŸèƒ½éªŒè¯æˆåŠŸ")


class TestConcurrentOperations:
    """å¹¶å‘æ“ä½œæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_concurrent_document_and_query(self, test_client: TestClient, test_utils: TestUtils):
        """æµ‹è¯•å¹¶å‘æ–‡æ¡£æ“ä½œå’ŒæŸ¥è¯¢"""
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        
        # æ–‡æ¡£æ’å…¥ä»»åŠ¡
        for i in range(5):
            doc_data = {
                "text": f"å¹¶å‘æµ‹è¯•æ–‡æ¡£{i}ï¼ŒåŒ…å«AIç›¸å…³å†…å®¹",
                "doc_id": f"concurrent_doc_{i}",
                "knowledge_base": "test_kb"
            }
            task = test_client.post(API_ENDPOINTS["document"]["insert_text"], json_data=doc_data)
            tasks.append(("insert", task))
        
        # æŸ¥è¯¢ä»»åŠ¡
        for i in range(3):
            query_data = {
                "query": f"å¹¶å‘æŸ¥è¯¢æµ‹è¯•{i}",
                "mode": "hybrid",
                "top_k": 3
            }
            task = test_client.post(API_ENDPOINTS["query"]["query"], json_data=query_data)
            tasks.append(("query", task))
        
        # é—®ç­”ä»»åŠ¡
        for i in range(2):
            qa_data = {
                "question": f"å¹¶å‘é—®ç­”æµ‹è¯•{i}ï¼Ÿ",
                "answer": f"å¹¶å‘é—®ç­”ç­”æ¡ˆ{i}",
                "category": "å¹¶å‘æµ‹è¯•"
            }
            task = test_client.post(API_ENDPOINTS["qa"]["pairs"], json_data=qa_data)
            tasks.append(("qa", task))
        
        # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*[task for _, task in tasks], return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = 0
        error_count = 0
        exception_count = 0
        
        for i, result in enumerate(results):
            task_type = tasks[i][0]
            if isinstance(result, Exception):
                exception_count += 1
                print(f"ä»»åŠ¡ {task_type} å¼‚å¸¸: {result}")
            elif result.status_code == 200:
                success_count += 1
            else:
                error_count += 1
                print(f"ä»»åŠ¡ {task_type} é”™è¯¯: {result.status_code}")
        
        print(f"å¹¶å‘æµ‹è¯•ç»“æœ: æˆåŠŸ={success_count}, é”™è¯¯={error_count}, å¼‚å¸¸={exception_count}")
        
        # å¤§éƒ¨åˆ†æ“ä½œåº”è¯¥æˆåŠŸ
        total_tasks = len(tasks)
        success_rate = success_count / total_tasks
        assert success_rate >= 0.6, f"å¹¶å‘æ“ä½œæˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"
    
    @pytest.mark.asyncio
    async def test_system_stability_under_load(self, test_client: TestClient, test_utils: TestUtils):
        """æµ‹è¯•è´Ÿè½½ä¸‹çš„ç³»ç»Ÿç¨³å®šæ€§"""
        
        # æŒç»­å‘é€è¯·æ±‚ä¸€æ®µæ—¶é—´
        duration = 10  # 10ç§’
        start_time = time.time()
        request_count = 0
        success_count = 0
        
        while time.time() - start_time < duration:
            # å‘é€å¥åº·æ£€æŸ¥è¯·æ±‚
            try:
                response = await test_client.get(API_ENDPOINTS["system"]["health"])
                request_count += 1
                if response.status_code == 200:
                    success_count += 1
            except Exception as e:
                print(f"è¯·æ±‚å¼‚å¸¸: {e}")
                request_count += 1
            
            # çŸ­æš‚å»¶è¿Ÿ
            await asyncio.sleep(0.1)
        
        print(f"è´Ÿè½½æµ‹è¯•: {request_count} ä¸ªè¯·æ±‚, {success_count} ä¸ªæˆåŠŸ")
        
        # è®¡ç®—æˆåŠŸç‡
        if request_count > 0:
            success_rate = success_count / request_count
            assert success_rate >= 0.8, f"è´Ÿè½½ä¸‹æˆåŠŸç‡è¿‡ä½: {success_rate:.2%}"
        
        # éªŒè¯ç³»ç»Ÿä»ç„¶å“åº”
        final_health = await test_client.get(API_ENDPOINTS["system"]["health"])
        test_utils.assert_response_success(final_health)
        print("âœ“ ç³»ç»Ÿåœ¨è´Ÿè½½åä»ç„¶ç¨³å®š")
