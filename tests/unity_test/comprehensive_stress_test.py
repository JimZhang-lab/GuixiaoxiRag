#!/usr/bin/env python3
"""
GuiXiaoXiRag ç³»ç»Ÿå…¨æ–¹ä½å‹æµ‹è„šæœ¬ - ä¼˜åŒ–ç‰ˆ
ä¸“ä¸º2000+ç”¨æˆ·é«˜å¹¶å‘åœºæ™¯è®¾è®¡ï¼Œæ”¯æŒå¤šç§æŸ¥è¯¢æ¨¡å¼å’Œå¯å˜æ–‡æœ¬é•¿åº¦æµ‹è¯•

ä¸»è¦æµ‹è¯•åŠŸèƒ½:
1. æ™ºèƒ½æŸ¥è¯¢æµ‹è¯• - æ”¯æŒ6ç§æŸ¥è¯¢æ¨¡å¼(local/global/hybrid/naive/mix/bypass)
2. å¯å˜é•¿åº¦æ–‡æœ¬æµ‹è¯• - 50-8000 tokensä¸ç­‰çš„æŸ¥è¯¢æ–‡æœ¬
3. cs_collegeçŸ¥è¯†åº“ä¸“é¡¹æµ‹è¯•
4. é—®ç­”ç³»ç»Ÿå‹åŠ›æµ‹è¯•
5. ç³»ç»Ÿæ€§èƒ½ç›‘æ§

ä½¿ç”¨æ–¹æ³•:
1. æ¿€æ´»ç¯å¢ƒ: conda activate guixiaoxi312
2. ç¡®ä¿æœåŠ¡è¿è¡Œåœ¨8002ç«¯å£
3. è¿è¡Œå‹æµ‹: python tests/stress_test.py

é«˜å¹¶å‘ä¼˜åŒ–ç‰¹æ€§:
- æ”¯æŒ2000+å¹¶å‘ç”¨æˆ·
- å¤šç§æŸ¥è¯¢æ¨¡å¼è¦†ç›–
- å¯å˜æ–‡æœ¬é•¿åº¦æµ‹è¯•
- è¿æ¥æ± ä¼˜åŒ–
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- å®æ—¶æ€§èƒ½ç›‘æ§
- è¯¦ç»†æµ‹è¯•æŠ¥å‘Š
- è‡ªåŠ¨æ•…éšœæ¢å¤
"""

import asyncio
import aiohttp
import time
import json
import random
import statistics
import psutil
import os
import sys
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import argparse
import logging
import gc
from collections import defaultdict, deque
import threading
import queue

# é…ç½®æ—¥å¿—
def setup_logging():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f'tests/stress_test_{timestamp}.log'
    
    # ç¡®ä¿testsç›®å½•å­˜åœ¨
    os.makedirs("tests", exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½® - é’ˆå¯¹é«˜å¹¶å‘ä¼˜åŒ–"""
    base_url: str = "http://localhost:8002"
    concurrent_users: int = 100  # é»˜è®¤100ï¼Œå¯æ‰©å±•åˆ°2000+
    test_duration: int = 600     # 10åˆ†é’Ÿæµ‹è¯•
    ramp_up_time: int = 60       # 1åˆ†é’Ÿé€æ­¥å¢åŠ è´Ÿè½½
    ramp_down_time: int = 30     # 30ç§’é€æ­¥å‡å°‘è´Ÿè½½
    
    # æµ‹è¯•æ¯”ä¾‹é…ç½®
    query_ratio: float = 0.70         # 70% æ™ºèƒ½æŸ¥è¯¢ï¼ˆå„ç§æ¨¡å¼ï¼‰
    qa_query_ratio: float = 0.15      # 15% é—®ç­”æŸ¥è¯¢
    qa_batch_ratio: float = 0.05      # 5% æ‰¹é‡æŸ¥è¯¢
    qa_create_ratio: float = 0.05     # 5% åˆ›å»ºé—®ç­”å¯¹
    health_ratio: float = 0.05        # 5% å¥åº·æ£€æŸ¥
    
    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    connection_pool_size: int = 500   # è¿æ¥æ± å¤§å°
    connection_per_host: int = 100    # æ¯ä¸ªä¸»æœºè¿æ¥æ•°
    request_timeout: int = 30         # è¯·æ±‚è¶…æ—¶
    max_retries: int = 3              # æœ€å¤§é‡è¯•æ¬¡æ•°

    # ç”¨æˆ·ä¸é™æµæ¨¡æ‹Ÿé…ç½®
    min_interval_per_user: float = 0.0  # å•ç”¨æˆ·æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶
    spoof_client_ip: bool = True        # æ˜¯å¦ä¸ºæ¯ä¸ªç”¨æˆ·ä¼ªé€ ä¸åŒçš„å®¢æˆ·ç«¯IP
    user_tier: str = "default"          # ç”¨æˆ·å¥—é¤ç­‰çº§ï¼šdefault/free/pro/enterprise

    # é”™è¯¯æ ·æœ¬é‡‡é›†
    error_sample_limit: int = 50        # æ¯ç±»é”™è¯¯é‡‡æ ·æ¡æ•°ä¸Šé™
    error_sample_size: int = 500        # æ¯æ¡æ ·æœ¬æœ€å¤§å­—ç¬¦æ•°

    # ç›‘æ§é…ç½®
    metrics_interval: int = 5         # æŒ‡æ ‡æ”¶é›†é—´éš”
    progress_report_interval: int = 30 # è¿›åº¦æŠ¥å‘Šé—´éš”

    # å†…å­˜ä¼˜åŒ–
    result_buffer_size: int = 10000   # ç»“æœç¼“å†²åŒºå¤§å°
    gc_interval: int = 100            # åƒåœ¾å›æ”¶é—´éš”

@dataclass
class TestResult:
    """å•æ¬¡æµ‹è¯•ç»“æœ - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
    endpoint: str
    method: str
    status_code: int
    response_time: float
    success: bool
    error_message: Optional[str] = None
    timestamp: float = 0.0
    user_id: int = 0
    
    def __post_init__(self):
        if self.timestamp == 0.0:
            self.timestamp = time.time()

@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_io_read_mb: float
    disk_io_write_mb: float
    network_sent_mb: float
    network_recv_mb: float
    active_connections: int = 0
    
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ - å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½"""
    
    def __init__(self, config: TestConfig):
        self.config = config
        self.metrics_queue = queue.Queue()
        self.is_monitoring = False
        self.monitor_thread = None
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        logger.info("ğŸ“Š æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("ğŸ“Š æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                metrics = self._collect_metrics()
                self.metrics_queue.put(metrics)
                time.sleep(self.config.metrics_interval)
            except Exception as e:
                logger.warning(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")
    
    def _collect_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used_mb = memory.used / (1024 * 1024)
        
        # ç£ç›˜IO
        disk_io = psutil.disk_io_counters()
        disk_io_read_mb = disk_io.read_bytes / (1024 * 1024) if disk_io else 0
        disk_io_write_mb = disk_io.write_bytes / (1024 * 1024) if disk_io else 0
        
        # ç½‘ç»œIO
        network_io = psutil.net_io_counters()
        network_sent_mb = network_io.bytes_sent / (1024 * 1024) if network_io else 0
        network_recv_mb = network_io.bytes_recv / (1024 * 1024) if network_io else 0
        
        # æ´»è·ƒè¿æ¥æ•°
        try:
            connections = psutil.net_connections()
            active_connections = len([c for c in connections if c.status == 'ESTABLISHED'])
        except:
            active_connections = 0
        
        return SystemMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory_percent,
            memory_used_mb=memory_used_mb,
            disk_io_read_mb=disk_io_read_mb,
            disk_io_write_mb=disk_io_write_mb,
            network_sent_mb=network_sent_mb,
            network_recv_mb=network_recv_mb,
            active_connections=active_connections
        )
    
    def get_all_metrics(self) -> List[SystemMetrics]:
        """è·å–æ‰€æœ‰æ”¶é›†çš„æŒ‡æ ‡"""
        metrics = []
        while not self.metrics_queue.empty():
            try:
                metrics.append(self.metrics_queue.get_nowait())
            except queue.Empty:
                break
        return metrics

class ResultBuffer:
    """ç»“æœç¼“å†²åŒº - ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.buffer = deque(maxlen=max_size)
        self.overflow_count = 0
        self.lock = threading.Lock()
    
    def add_result(self, result: TestResult):
        """æ·»åŠ æµ‹è¯•ç»“æœ"""
        with self.lock:
            if len(self.buffer) >= self.max_size:
                self.overflow_count += 1
            self.buffer.append(result)
    
    def get_all_results(self) -> List[TestResult]:
        """è·å–æ‰€æœ‰ç»“æœ"""
        with self.lock:
            return list(self.buffer)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å†²åŒºç»Ÿè®¡"""
        with self.lock:
            return {
                "buffer_size": len(self.buffer),
                "max_size": self.max_size,
                "overflow_count": self.overflow_count
            }

class HighConcurrencyStressTest:
    """é«˜å¹¶å‘å‹åŠ›æµ‹è¯•å™¨"""

    def __init__(self, config: TestConfig):
        self.config = config
        self.result_buffer = ResultBuffer(config.result_buffer_size)
        self.performance_monitor = PerformanceMonitor(config)
        self.session: Optional[aiohttp.ClientSession] = None
        self.start_time = 0.0
        self.end_time = 0.0
        self.active_users = 0
        self.total_requests = 0
        self.request_counter_lock = threading.Lock()
        # å¤±è´¥æ ·æœ¬æ”¶é›†ï¼ˆæŒ‰ endpoint::HTTP<code> èšåˆï¼‰
        self.error_samples = defaultdict(list)

        # æµ‹è¯•æ•°æ® - æ‰©å±•æµ‹è¯•æ•°æ®
        self.test_questions = self._generate_test_questions()
        self.qa_pairs_data = self._generate_qa_pairs_data()
        self.query_modes = ["local", "global", "hybrid", "naive", "mix", "bypass"]
        self.performance_modes = ["fast", "balanced", "quality"]
        self.variable_length_queries = self._generate_variable_length_queries()

    def _build_user_headers(self, user_id: int, request_count: int = 0) -> Dict[str, str]:
        """æ„é€ æ¯ä¸ªè¯·æ±‚çš„ç”¨æˆ·ä¸ä»£ç†ç›¸å…³å¤´éƒ¨"""
        headers: Dict[str, str] = {}
        if self.config.spoof_client_ip:
            a = 10
            b = user_id % 255
            c = (user_id // 255) % 255
            d = request_count % 255
            fake_ip = f"{a}.{b}.{c}.{d}"
            headers["X-Forwarded-For"] = fake_ip
            headers["X-Real-IP"] = fake_ip
        headers["X-User-Id"] = str(user_id)
        headers["X-Client-Id"] = f"stress-user-{user_id}"
        if getattr(self.config, "user_tier", None):
            headers["X-User-Tier"] = self.config.user_tier
        return headers

    async def _handle_response_and_backoff(self, endpoint: str, response: aiohttp.ClientResponse, response_time: float, user_id: int, request_count: int, is_warmup: bool) -> TestResult:
        """ç»Ÿä¸€å¤„ç†å“åº”ã€é‡‡æ ·é”™è¯¯ã€å¹¶å¯¹ 429 åšæŒ‡æ•°é€€é¿"""
        status = response.status
        error_msg = None
        success = False
        try:
            data = await response.json()
            success = bool(data.get("success", status == 200))
            if not success:
                error_msg = data.get("message") or data.get("error") or f"HTTP {status}"
                # é‡‡æ ·é”™è¯¯å“åº”ä½“
                self._record_error_sample(endpoint, status, json.dumps(data, ensure_ascii=False)[:1000])
        except Exception:
            text = await response.text()
            success = (status == 200)
            if not success:
                error_msg = f"HTTP {status}"
                self._record_error_sample(endpoint, status, text[:1000])

        result = TestResult(
            endpoint=endpoint,
            method=response.method if hasattr(response, 'method') else 'POST',
            status_code=status,
            response_time=response_time,
            success=success,
            error_message=error_msg,
            user_id=user_id
        )

        if not is_warmup:
            self.result_buffer.add_result(result)
            self.increment_request_counter()

        # å¯¹ 429 åšæŒ‡æ•°é€€é¿ï¼Œé¿å…é›ªå´©ï¼ˆä»…éé¢„çƒ­é˜¶æ®µï¼‰
        if status == 429 and not is_warmup:
            backoff_base = 0.2
            attempt = min(request_count, 6)
            await asyncio.sleep(backoff_base * (2 ** attempt))

        # å•ç”¨æˆ·æœ€å°è¯·æ±‚é—´éš”
        if self.config.min_interval_per_user and not is_warmup:
            await asyncio.sleep(self.config.min_interval_per_user)

        return result

    def _record_error_sample(self, endpoint: str, status_code: int, sample_text: str):
        """è®°å½•å¤±è´¥å“åº”çš„æ ·æœ¬ï¼ˆé™é•¿ã€é™é‡ï¼‰"""
        key = f"{endpoint}::HTTP{status_code}"
        limit = getattr(self.config, "error_sample_limit", 50)
        size = getattr(self.config, "error_sample_size", 500)
        if len(self.error_samples[key]) < limit:
            snippet = (sample_text or "").strip()
            if len(snippet) > size:
                snippet = snippet[:size] + "..."
            self.error_samples[key].append(snippet)

    def _generate_test_questions(self) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•é—®é¢˜"""
        base_questions = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "æ·±åº¦å­¦ä¹ å’Œä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Ÿ",
            "è®¡ç®—æœºè§†è§‰çš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ",
            "å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¤§æ•°æ®åˆ†æçš„ä¸»è¦æŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
            "äº‘è®¡ç®—çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
            "åŒºå—é“¾æŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ç‰©è”ç½‘çš„å‘å±•è¶‹åŠ¿å¦‚ä½•ï¼Ÿ",
            "5GæŠ€æœ¯å¸¦æ¥äº†å“ªäº›å˜åŒ–ï¼Ÿ",
            "é‡å­è®¡ç®—çš„æ½œåœ¨åº”ç”¨æœ‰å“ªäº›ï¼Ÿ",
            "ç½‘ç»œå®‰å…¨çš„é‡è¦æ€§ä½“ç°åœ¨å“ªé‡Œï¼Ÿ",
            "æ•°æ®æŒ–æ˜çš„å¸¸ç”¨ç®—æ³•æœ‰å“ªäº›ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯è¾¹ç¼˜è®¡ç®—ï¼Ÿ",
            "å®¹å™¨åŒ–æŠ€æœ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
            "å¾®æœåŠ¡æ¶æ„çš„ç‰¹ç‚¹æœ‰å“ªäº›ï¼Ÿ",
            "DevOpsçš„æ ¸å¿ƒç†å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
            "ä»€ä¹ˆæ˜¯æ•°å­—åŒ–è½¬å‹ï¼Ÿ"
        ]
        
        # æ‰©å±•é—®é¢˜åˆ—è¡¨ï¼Œå¢åŠ å˜ä½“
        extended_questions = []
        for question in base_questions:
            extended_questions.append(question)
            # æ·»åŠ å˜ä½“
            extended_questions.append(f"è¯·è¯¦ç»†è§£é‡Š{question}")
            extended_questions.append(f"èƒ½å¦ç®€å•ä»‹ç»ä¸€ä¸‹{question}")
            extended_questions.append(f"å…³äº{question}ï¼Œä½ äº†è§£å¤šå°‘ï¼Ÿ")
        
        return extended_questions

    def _generate_qa_pairs_data(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé—®ç­”å¯¹æµ‹è¯•æ•°æ®"""
        base_pairs = [
            {
                "question": "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
                "answer": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚",
                "category": "programming",
                "confidence": 0.95,
                "keywords": ["Python", "ç¼–ç¨‹è¯­è¨€"],
                "source": "stress_test"
            },
            {
                "question": "ä»€ä¹ˆæ˜¯æ•°æ®ç»“æ„ï¼Ÿ",
                "answer": "æ•°æ®ç»“æ„æ˜¯è®¡ç®—æœºå­˜å‚¨ã€ç»„ç»‡æ•°æ®çš„æ–¹å¼ï¼ŒåŒ…æ‹¬æ•°ç»„ã€é“¾è¡¨ã€æ ˆã€é˜Ÿåˆ—ç­‰ã€‚",
                "category": "computer_science",
                "confidence": 0.92,
                "keywords": ["æ•°æ®ç»“æ„", "ç®—æ³•"],
                "source": "stress_test"
            },
            {
                "question": "ä»€ä¹ˆæ˜¯APIï¼Ÿ",
                "answer": "APIï¼ˆåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼‰æ˜¯ä¸åŒè½¯ä»¶åº”ç”¨ç¨‹åºä¹‹é—´è¿›è¡Œé€šä¿¡çš„æ¥å£ã€‚",
                "category": "technology",
                "confidence": 0.90,
                "keywords": ["API", "æ¥å£"],
                "source": "stress_test"
            },
            {
                "question": "ä»€ä¹ˆæ˜¯æ•°æ®åº“ï¼Ÿ",
                "answer": "æ•°æ®åº“æ˜¯å­˜å‚¨å’Œç®¡ç†æ•°æ®çš„ç³»ç»Ÿï¼Œæä¾›æ•°æ®çš„å¢åˆ æ”¹æŸ¥åŠŸèƒ½ã€‚",
                "category": "database",
                "confidence": 0.93,
                "keywords": ["æ•°æ®åº“", "å­˜å‚¨"],
                "source": "stress_test"
            },
            {
                "question": "ä»€ä¹ˆæ˜¯äº‘è®¡ç®—ï¼Ÿ",
                "answer": "äº‘è®¡ç®—æ˜¯é€šè¿‡äº’è”ç½‘æä¾›è®¡ç®—èµ„æºå’ŒæœåŠ¡çš„æ¨¡å¼ã€‚",
                "category": "cloud",
                "confidence": 0.91,
                "keywords": ["äº‘è®¡ç®—", "äº’è”ç½‘"],
                "source": "stress_test"
            }
        ]
        return base_pairs

    def _generate_variable_length_queries(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆä¸åŒé•¿åº¦çš„æŸ¥è¯¢æ–‡æœ¬ (50-8000 tokens)"""

        # åŸºç¡€æŸ¥è¯¢æ¨¡æ¿
        base_topics = [
            "è®¡ç®—æœºç§‘å­¦", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "æ•°æ®ç§‘å­¦", "è½¯ä»¶å·¥ç¨‹",
            "ç½‘ç»œå®‰å…¨", "äº‘è®¡ç®—", "å¤§æ•°æ®", "åŒºå—é“¾", "ç‰©è”ç½‘", "é‡å­è®¡ç®—",
            "ç¼–ç¨‹è¯­è¨€", "ç®—æ³•è®¾è®¡", "æ•°æ®ç»“æ„", "æ“ä½œç³»ç»Ÿ", "æ•°æ®åº“ç³»ç»Ÿ", "åˆ†å¸ƒå¼ç³»ç»Ÿ"
        ]

        # æ‰©å±•å†…å®¹ç‰‡æ®µ
        content_fragments = [
            "çš„åŸºæœ¬æ¦‚å¿µå’Œæ ¸å¿ƒåŸç†", "åœ¨ç°ä»£ç§‘æŠ€å‘å±•ä¸­çš„é‡è¦ä½œç”¨", "çš„å†å²å‘å±•è¿‡ç¨‹å’Œé‡Œç¨‹ç¢‘äº‹ä»¶",
            "çš„æŠ€æœ¯å®ç°æ–¹æ³•å’Œå…³é”®æŠ€æœ¯", "åœ¨å„ä¸ªè¡Œä¸šä¸­çš„å®é™…åº”ç”¨æ¡ˆä¾‹", "é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ",
            "çš„æœªæ¥å‘å±•è¶‹åŠ¿å’Œå‰æ™¯å±•æœ›", "ä¸å…¶ä»–æŠ€æœ¯é¢†åŸŸçš„äº¤å‰èåˆ", "å¯¹ç¤¾ä¼šç»æµå‘å±•çš„æ·±è¿œå½±å“",
            "çš„ç†è®ºåŸºç¡€å’Œæ•°å­¦æ¨¡å‹", "çš„å·¥ç¨‹å®è·µå’Œé¡¹ç›®ç®¡ç†", "çš„æ ‡å‡†åŒ–å’Œè§„èŒƒåŒ–è¿›ç¨‹",
            "çš„å®‰å…¨æ€§å’Œå¯é æ€§è€ƒè™‘", "çš„æ€§èƒ½ä¼˜åŒ–å’Œæ•ˆç‡æå‡", "çš„æˆæœ¬æ•ˆç›Šåˆ†æå’ŒæŠ•èµ„å›æŠ¥",
            "çš„äººæ‰åŸ¹å…»å’Œæ•™è‚²ä½“ç³»", "çš„å›½é™…åˆä½œå’ŒæŠ€æœ¯äº¤æµ", "çš„æ³•å¾‹æ³•è§„å’Œä¼¦ç†è€ƒé‡"
        ]

        # è¯¦ç»†æè¿°ç‰‡æ®µ
        detailed_fragments = [
            "ä»æŠ€æœ¯æ¶æ„çš„è§’åº¦æ¥çœ‹ï¼Œè¿™ä¸ªé¢†åŸŸæ¶‰åŠå¤šä¸ªå±‚æ¬¡çš„å¤æ‚ç³»ç»Ÿè®¾è®¡ï¼ŒåŒ…æ‹¬åº•å±‚ç¡¬ä»¶ä¼˜åŒ–ã€ä¸­é—´ä»¶é›†æˆã€ä¸Šå±‚åº”ç”¨å¼€å‘ç­‰å„ä¸ªç¯èŠ‚ã€‚",
            "åœ¨å®é™…åº”ç”¨è¿‡ç¨‹ä¸­ï¼Œéœ€è¦è€ƒè™‘ç”¨æˆ·ä½“éªŒã€ç³»ç»Ÿæ€§èƒ½ã€æ•°æ®å®‰å…¨ã€æˆæœ¬æ§åˆ¶ç­‰å¤šä¸ªç»´åº¦çš„å¹³è¡¡å’Œä¼˜åŒ–ã€‚",
            "éšç€æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥å’Œå¸‚åœºéœ€æ±‚çš„å˜åŒ–ï¼Œç›¸å…³çš„æ ‡å‡†å’Œè§„èŒƒä¹Ÿåœ¨æŒç»­æ¼”è¿›å’Œå®Œå–„ã€‚",
            "äº§ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„ç´§å¯†åˆä½œæ¨åŠ¨äº†ç†è®ºç ”ç©¶å’Œå®è·µåº”ç”¨çš„ç›¸äº’ä¿ƒè¿›å’Œå…±åŒå‘å±•ã€‚",
            "å›½é™…åŒ–çš„æŠ€æœ¯äº¤æµå’Œæ ‡å‡†åˆ¶å®šä¸ºå…¨çƒèŒƒå›´å†…çš„æŠ€æœ¯åˆ›æ–°å’Œåº”ç”¨æ¨å¹¿æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
            "è·¨å­¦ç§‘çš„ç ”ç©¶æ–¹æ³•å’Œå¤šå…ƒåŒ–çš„æŠ€æœ¯è·¯å¾„ä¸ºè§£å†³å¤æ‚é—®é¢˜æä¾›äº†æ›´å¤šçš„å¯èƒ½æ€§å’Œé€‰æ‹©ã€‚",
            "å¯æŒç»­å‘å±•çš„ç†å¿µå’Œç»¿è‰²æŠ€æœ¯çš„åº”ç”¨æˆä¸ºäº†ç°ä»£æŠ€æœ¯å‘å±•çš„é‡è¦è€ƒé‡å› ç´ ã€‚",
            "æ•°å­—åŒ–è½¬å‹å’Œæ™ºèƒ½åŒ–å‡çº§ä¸ºä¼ ç»Ÿè¡Œä¸šå¸¦æ¥äº†æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚"
        ]

        queries_by_length = {
            "short": [],      # 50-200 tokens
            "medium": [],     # 200-800 tokens
            "long": [],       # 800-2000 tokens
            "very_long": [],  # 2000-5000 tokens
            "ultra_long": []  # 5000-8000 tokens
        }

        # ç”ŸæˆçŸ­æŸ¥è¯¢ (50-200 tokens)
        for topic in base_topics:
            for fragment in content_fragments[:6]:
                query = f"è¯·è¯¦ç»†ä»‹ç»{topic}{fragment}ï¼ŒåŒ…æ‹¬ç›¸å…³çš„æŠ€æœ¯ç»†èŠ‚ã€åº”ç”¨åœºæ™¯å’Œå‘å±•ç°çŠ¶ã€‚"
                queries_by_length["short"].append(query)

        # ç”Ÿæˆä¸­ç­‰é•¿åº¦æŸ¥è¯¢ (200-800 tokens)
        for topic in base_topics[:10]:
            query_parts = [
                f"å…³äº{topic}è¿™ä¸ªé‡è¦çš„æŠ€æœ¯é¢†åŸŸï¼Œæˆ‘æƒ³äº†è§£ä»¥ä¸‹å‡ ä¸ªæ–¹é¢çš„å†…å®¹ï¼š",
                f"1. {topic}çš„æ ¸å¿ƒæ¦‚å¿µå’ŒåŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
                f"2. {topic}åœ¨å½“å‰æŠ€æœ¯å‘å±•ä¸­å¤„äºä»€ä¹ˆåœ°ä½ï¼Ÿ",
                f"3. {topic}æœ‰å“ªäº›ä¸»è¦çš„åº”ç”¨é¢†åŸŸå’Œå®é™…æ¡ˆä¾‹ï¼Ÿ",
                f"4. {topic}é¢ä¸´çš„ä¸»è¦æŠ€æœ¯æŒ‘æˆ˜æœ‰å“ªäº›ï¼Ÿ",
                f"5. {topic}çš„æœªæ¥å‘å±•æ–¹å‘å’Œè¶‹åŠ¿å¦‚ä½•ï¼Ÿ",
                "è¯·é’ˆå¯¹æ¯ä¸ªé—®é¢˜æä¾›è¯¦ç»†çš„åˆ†æå’Œè¯´æ˜ï¼Œå¹¶ç»“åˆå…·ä½“çš„æŠ€æœ¯å®ä¾‹è¿›è¡Œé˜è¿°ã€‚"
            ]
            query = " ".join(query_parts)
            queries_by_length["medium"].append(query)

        # ç”Ÿæˆé•¿æŸ¥è¯¢ (800-2000 tokens)
        for topic in base_topics[:8]:
            query_parts = [
                f"æˆ‘æ­£åœ¨è¿›è¡Œå…³äº{topic}çš„æ·±å…¥ç ”ç©¶ï¼Œå¸Œæœ›èƒ½å¤Ÿè·å¾—å…¨é¢è€Œè¯¦ç»†çš„ä¿¡æ¯ã€‚",
                f"é¦–å…ˆï¼Œè¯·ä»‹ç»{topic}çš„å†å²å‘å±•è„‰ç»œï¼ŒåŒ…æ‹¬é‡è¦çš„é‡Œç¨‹ç¢‘äº‹ä»¶å’Œå…³é”®æŠ€æœ¯çªç ´ã€‚",
                f"å…¶æ¬¡ï¼Œè¯·è¯¦ç»†é˜è¿°{topic}çš„æ ¸å¿ƒæŠ€æœ¯åŸç†å’Œç†è®ºåŸºç¡€ï¼ŒåŒ…æ‹¬ç›¸å…³çš„æ•°å­¦æ¨¡å‹å’Œç®—æ³•è®¾è®¡ã€‚",
                f"ç¬¬ä¸‰ï¼Œè¯·åˆ†æ{topic}åœ¨ä¸åŒè¡Œä¸šå’Œé¢†åŸŸä¸­çš„åº”ç”¨æƒ…å†µï¼ŒåŒ…æ‹¬æˆåŠŸæ¡ˆä¾‹å’Œå¤±è´¥æ•™è®­ã€‚",
                f"ç¬¬å››ï¼Œè¯·è®¨è®º{topic}å½“å‰é¢ä¸´çš„ä¸»è¦æŠ€æœ¯æŒ‘æˆ˜å’Œç“¶é¢ˆï¼Œä»¥åŠå¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚",
                f"ç¬¬äº”ï¼Œè¯·å±•æœ›{topic}çš„æœªæ¥å‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬æ–°å…´æŠ€æœ¯çš„èåˆå’Œåˆ›æ–°æ–¹å‘ã€‚",
                f"æœ€åï¼Œè¯·åˆ†æ{topic}å¯¹ç¤¾ä¼šç»æµå‘å±•çš„å½±å“ï¼ŒåŒ…æ‹¬å°±ä¸šã€æ•™è‚²ã€äº§ä¸šç»“æ„ç­‰æ–¹é¢çš„å˜åŒ–ã€‚",
                "è¯·ç¡®ä¿å›ç­”å†…å®¹çš„å‡†ç¡®æ€§å’Œæƒå¨æ€§ï¼Œå¹¶æä¾›ç›¸å…³çš„æ•°æ®æ”¯æ’‘å’Œæ¡ˆä¾‹åˆ†æã€‚"
            ]
            for fragment in detailed_fragments[:3]:
                query_parts.append(fragment)
            query = " ".join(query_parts)
            queries_by_length["long"].append(query)

        # ç”Ÿæˆå¾ˆé•¿æŸ¥è¯¢ (2000-5000 tokens)
        for topic in base_topics[:5]:
            query_parts = [
                f"ä½œä¸º{topic}é¢†åŸŸçš„ç ”ç©¶è€…ï¼Œæˆ‘éœ€è¦å¯¹è¿™ä¸ªé¢†åŸŸè¿›è¡Œå…¨æ–¹ä½çš„æ·±åº¦åˆ†æå’Œç ”ç©¶ã€‚",
                f"è¯·ä»ä»¥ä¸‹å¤šä¸ªç»´åº¦å¯¹{topic}è¿›è¡Œè¯¦ç»†çš„é˜è¿°å’Œåˆ†æï¼š",
                "",
                "ä¸€ã€å†å²å‘å±•ç»´åº¦ï¼š",
                f"1.1 {topic}çš„èµ·æºå’Œæ—©æœŸå‘å±•é˜¶æ®µ",
                f"1.2 {topic}å‘å±•è¿‡ç¨‹ä¸­çš„é‡è¦é‡Œç¨‹ç¢‘å’Œè½¬æŠ˜ç‚¹",
                f"1.3 {topic}é¢†åŸŸçš„é‡è¦äººç‰©å’Œè´¡çŒ®",
                f"1.4 {topic}ä¸å…¶ä»–å­¦ç§‘é¢†åŸŸçš„äº¤å‰å‘å±•",
                "",
                "äºŒã€æŠ€æœ¯åŸç†ç»´åº¦ï¼š",
                f"2.1 {topic}çš„æ ¸å¿ƒç†è®ºåŸºç¡€å’Œæ•°å­¦æ¨¡å‹",
                f"2.2 {topic}çš„å…³é”®æŠ€æœ¯å’Œå®ç°æ–¹æ³•",
                f"2.3 {topic}çš„æŠ€æœ¯æ¶æ„å’Œç³»ç»Ÿè®¾è®¡",
                f"2.4 {topic}çš„æ€§èƒ½è¯„ä¼°å’Œä¼˜åŒ–ç­–ç•¥",
                "",
                "ä¸‰ã€åº”ç”¨å®è·µç»´åº¦ï¼š",
                f"3.1 {topic}åœ¨å„ä¸ªè¡Œä¸šä¸­çš„å…·ä½“åº”ç”¨",
                f"3.2 {topic}çš„æˆåŠŸæ¡ˆä¾‹å’Œæœ€ä½³å®è·µ",
                f"3.3 {topic}çš„å®æ–½æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ",
                f"3.4 {topic}çš„æŠ•èµ„å›æŠ¥å’Œç»æµæ•ˆç›Š",
                "",
                "å››ã€å‘å±•è¶‹åŠ¿ç»´åº¦ï¼š",
                f"4.1 {topic}çš„æŠ€æœ¯å‘å±•è¶‹åŠ¿å’Œåˆ›æ–°æ–¹å‘",
                f"4.2 {topic}ä¸æ–°å…´æŠ€æœ¯çš„èåˆå‘å±•",
                f"4.3 {topic}çš„å¸‚åœºå‰æ™¯å’Œå•†ä¸šæ¨¡å¼",
                f"4.4 {topic}çš„æ ‡å‡†åŒ–å’Œè§„èŒƒåŒ–è¿›ç¨‹",
                "",
                "äº”ã€ç¤¾ä¼šå½±å“ç»´åº¦ï¼š",
                f"5.1 {topic}å¯¹å°±ä¸šå¸‚åœºå’Œäººæ‰éœ€æ±‚çš„å½±å“",
                f"5.2 {topic}å¯¹æ•™è‚²ä½“ç³»å’ŒåŸ¹å…»æ¨¡å¼çš„å½±å“",
                f"5.3 {topic}å¯¹ç¤¾ä¼šç»“æ„å’Œç”Ÿæ´»æ–¹å¼çš„å½±å“",
                f"5.4 {topic}çš„ä¼¦ç†è€ƒé‡å’Œç¤¾ä¼šè´£ä»»",
            ]
            for fragment in detailed_fragments:
                query_parts.append(fragment)
            query_parts.extend([
                "è¯·ç¡®ä¿å›ç­”å†…å®¹çš„ç³»ç»Ÿæ€§å’Œå®Œæ•´æ€§ï¼Œæä¾›å……åˆ†çš„æ•°æ®æ”¯æ’‘å’Œæ¡ˆä¾‹åˆ†æã€‚",
                "åŒæ—¶ï¼Œè¯·æ³¨æ„å†…å®¹çš„å‰æ²¿æ€§å’Œå®ç”¨æ€§ï¼Œç»“åˆæœ€æ–°çš„ç ”ç©¶æˆæœå’Œè¡Œä¸šåŠ¨æ€ã€‚"
            ])
            query = " ".join(query_parts)
            queries_by_length["very_long"].append(query)

        # ç”Ÿæˆè¶…é•¿æŸ¥è¯¢ (5000-8000 tokens)
        for topic in base_topics[:3]:
            query_parts = [
                f"æˆ‘æ­£åœ¨æ’°å†™å…³äº{topic}çš„ç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šï¼Œéœ€è¦å¯¹è¿™ä¸ªé¢†åŸŸè¿›è¡Œæå…¶è¯¦ç»†å’Œå…¨é¢çš„åˆ†æã€‚",
                f"è¯·ä»å­¦æœ¯ç ”ç©¶ã€äº§ä¸šåº”ç”¨ã€æŠ€æœ¯å‘å±•ã€ç¤¾ä¼šå½±å“ç­‰å¤šä¸ªè§’åº¦å¯¹{topic}è¿›è¡Œæ·±åº¦å‰–æï¼š",
                "",
                "ç¬¬ä¸€éƒ¨åˆ†ï¼šç†è®ºåŸºç¡€ä¸å­¦æœ¯ç ”ç©¶",
                f"1.1 {topic}çš„ç†è®ºèµ·æºå’Œå“²å­¦åŸºç¡€",
                f"1.2 {topic}çš„æ ¸å¿ƒæ¦‚å¿µä½“ç³»å’Œåˆ†ç±»æ¡†æ¶",
                f"1.3 {topic}çš„æ•°å­¦æ¨¡å‹å’Œç®—æ³•ç†è®º",
                f"1.4 {topic}çš„ç ”ç©¶æ–¹æ³•è®ºå’Œå®éªŒè®¾è®¡",
                f"1.5 {topic}é¢†åŸŸçš„é‡è¦å­¦æœ¯æœºæ„å’Œç ”ç©¶å›¢é˜Ÿ",
                f"1.6 {topic}çš„å­¦æœ¯æœŸåˆŠå’Œä¼šè®®ä½“ç³»",
                f"1.7 {topic}çš„çŸ¥è¯†äº§æƒå’Œä¸“åˆ©åˆ†æ",
                "",
                "ç¬¬äºŒéƒ¨åˆ†ï¼šæŠ€æœ¯å®ç°ä¸å·¥ç¨‹åº”ç”¨",
                f"2.1 {topic}çš„æŠ€æœ¯æ¶æ„å’Œç³»ç»Ÿè®¾è®¡åŸåˆ™",
                f"2.2 {topic}çš„æ ¸å¿ƒç®—æ³•å’Œå®ç°æŠ€æœ¯",
                f"2.3 {topic}çš„å¼€å‘å·¥å…·å’Œå¹³å°ç”Ÿæ€",
                f"2.4 {topic}çš„æ€§èƒ½ä¼˜åŒ–å’Œæ‰©å±•æ€§è®¾è®¡",
                f"2.5 {topic}çš„å®‰å…¨æ€§å’Œå¯é æ€§ä¿éšœ",
                f"2.6 {topic}çš„æµ‹è¯•éªŒè¯å’Œè´¨é‡æ§åˆ¶",
                f"2.7 {topic}çš„éƒ¨ç½²è¿ç»´å’Œç›‘æ§ç®¡ç†",
                "",
                "ç¬¬ä¸‰éƒ¨åˆ†ï¼šäº§ä¸šåº”ç”¨ä¸å•†ä¸šä»·å€¼",
                f"3.1 {topic}åœ¨é‡‘èæœåŠ¡ä¸šçš„åº”ç”¨å’Œåˆ›æ–°",
                f"3.2 {topic}åœ¨åˆ¶é€ ä¸šçš„æ•°å­—åŒ–è½¬å‹åº”ç”¨",
                f"3.3 {topic}åœ¨åŒ»ç–—å¥åº·é¢†åŸŸçš„çªç ´æ€§åº”ç”¨",
                f"3.4 {topic}åœ¨æ•™è‚²åŸ¹è®­è¡Œä¸šçš„å˜é©æ€§åº”ç”¨",
                f"3.5 {topic}åœ¨äº¤é€šç‰©æµé¢†åŸŸçš„æ™ºèƒ½åŒ–åº”ç”¨",
                f"3.6 {topic}åœ¨èƒ½æºç¯ä¿è¡Œä¸šçš„å¯æŒç»­å‘å±•åº”ç”¨",
                f"3.7 {topic}çš„å•†ä¸šæ¨¡å¼åˆ›æ–°å’Œä»·å€¼é“¾é‡æ„",
                "",
                "ç¬¬å››éƒ¨åˆ†ï¼šå‘å±•è¶‹åŠ¿ä¸æœªæ¥å±•æœ›",
                f"4.1 {topic}çš„æŠ€æœ¯å‘å±•è·¯çº¿å›¾å’Œé‡Œç¨‹ç¢‘è§„åˆ’",
                f"4.2 {topic}ä¸äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æ·±åº¦èåˆ",
                f"4.3 {topic}ä¸ç‰©è”ç½‘æŠ€æœ¯çš„ååŒå‘å±•",
                f"4.4 {topic}ä¸åŒºå—é“¾æŠ€æœ¯çš„åˆ›æ–°ç»“åˆ",
                f"4.5 {topic}ä¸é‡å­è®¡ç®—çš„å‰æ²¿æ¢ç´¢",
                f"4.6 {topic}çš„å›½é™…æ ‡å‡†åŒ–å’Œè§„èŒƒåŒ–è¿›ç¨‹",
                f"4.7 {topic}çš„å…¨çƒåŒ–å‘å±•å’Œå›½é™…åˆä½œ",
                "",
                "ç¬¬äº”éƒ¨åˆ†ï¼šæŒ‘æˆ˜åˆ†æä¸è§£å†³ç­–ç•¥",
                f"5.1 {topic}é¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜å’Œç“¶é¢ˆåˆ†æ",
                f"5.2 {topic}çš„äººæ‰çŸ­ç¼ºå’ŒåŸ¹å…»ä½“ç³»å»ºè®¾",
                f"5.3 {topic}çš„æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤é—®é¢˜",
                f"5.4 {topic}çš„ä¼¦ç†é“å¾·å’Œç¤¾ä¼šè´£ä»»è€ƒé‡",
                f"5.5 {topic}çš„æ³•å¾‹æ³•è§„å’Œæ”¿ç­–ç¯å¢ƒ",
                f"5.6 {topic}çš„æŠ•èµ„é£é™©å’Œå¸‚åœºä¸ç¡®å®šæ€§",
                f"5.7 {topic}çš„å¯æŒç»­å‘å±•å’Œç¯å¢ƒå½±å“",
                "",
                "ç¬¬å…­éƒ¨åˆ†ï¼šç¤¾ä¼šå½±å“ä¸å˜é©æ„ä¹‰",
                f"6.1 {topic}å¯¹åŠ³åŠ¨åŠ›å¸‚åœºå’Œå°±ä¸šç»“æ„çš„å½±å“",
                f"6.2 {topic}å¯¹æ•™è‚²ä½“ç³»å’Œäººæ‰åŸ¹å…»çš„å˜é©",
                f"6.3 {topic}å¯¹ç¤¾ä¼šæ²»ç†å’Œå…¬å…±æœåŠ¡çš„æå‡",
                f"6.4 {topic}å¯¹ç»æµå‘å±•æ¨¡å¼çš„é‡å¡‘",
                f"6.5 {topic}å¯¹æ–‡åŒ–ä¼ æ’­å’Œç¤¾ä¼šäº¤å¾€çš„å½±å“",
                f"6.6 {topic}å¯¹åŸå¸‚è§„åˆ’å’Œæ™ºæ…§åŸå¸‚å»ºè®¾çš„æ¨åŠ¨",
                f"6.7 {topic}å¯¹å…¨çƒåŒ–è¿›ç¨‹å’Œå›½é™…å…³ç³»çš„å½±å“",
            ]

            # æ·»åŠ æ›´å¤šè¯¦ç»†å†…å®¹
            for i, fragment in enumerate(detailed_fragments):
                query_parts.append(f"è¡¥å……è¯´æ˜{i+1}ï¼š{fragment}")

            query_parts.extend([
                "",
                "è¯·ç¡®ä¿å›ç­”å†…å®¹å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š",
                "- å­¦æœ¯ä¸¥è°¨æ€§ï¼šåŸºäºæƒå¨èµ„æ–™å’Œæœ€æ–°ç ”ç©¶æˆæœ",
                "- å®è·µæŒ‡å¯¼æ€§ï¼šç»“åˆå…·ä½“æ¡ˆä¾‹å’Œå®é™…åº”ç”¨ç»éªŒ",
                "- å‰ç»é¢„æµ‹æ€§ï¼šæŠŠæ¡æŠ€æœ¯å‘å±•è¶‹åŠ¿å’Œæœªæ¥æ–¹å‘",
                "- ç³»ç»Ÿå®Œæ•´æ€§ï¼šè¦†ç›–ç†è®ºã€æŠ€æœ¯ã€åº”ç”¨ã€å½±å“ç­‰å„ä¸ªå±‚é¢",
                "- æ•°æ®æ”¯æ’‘æ€§ï¼šæä¾›å……åˆ†çš„ç»Ÿè®¡æ•°æ®å’Œé‡åŒ–åˆ†æ",
                "- å›½é™…è§†é‡æ€§ï¼šç»“åˆå…¨çƒå‘å±•ç°çŠ¶å’Œå›½é™…æ¯”è¾ƒ",
                "- åˆ›æ–°å¯å‘æ€§ï¼šæå‡ºæ–°çš„æ€è€ƒè§’åº¦å’Œå‘å±•å»ºè®®",
                "",
                "åŒæ—¶ï¼Œè¯·åœ¨å›ç­”ä¸­æ³¨æ˜ä¿¡æ¯æ¥æºå’Œå‚è€ƒæ–‡çŒ®ï¼Œç¡®ä¿å†…å®¹çš„å¯ä¿¡åº¦å’Œå¯è¿½æº¯æ€§ã€‚"
            ])

            query = " ".join(query_parts)
            queries_by_length["ultra_long"].append(query)

        return queries_by_length

    def get_user_specific_query_config(self, user_id: int, request_count: int) -> Dict[str, Any]:
        """ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆç‰¹å®šçš„æŸ¥è¯¢é…ç½®ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰æ¨¡å¼å’Œé•¿åº¦"""

        # ç¡®ä¿æ¯ä¸ªç”¨æˆ·åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ä¼šè½®æ¢ä½¿ç”¨æ‰€æœ‰æŸ¥è¯¢æ¨¡å¼
        mode_index = (user_id * 7 + request_count) % len(self.query_modes)
        query_mode = self.query_modes[mode_index]

        # ç¡®ä¿æ¯ä¸ªç”¨æˆ·åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ä¼šä½¿ç”¨ä¸åŒé•¿åº¦çš„æ–‡æœ¬
        length_categories = list(self.variable_length_queries.keys())
        length_index = (user_id * 3 + request_count // 2) % len(length_categories)
        length_category = length_categories[length_index]

        # æ€§èƒ½æ¨¡å¼ä¹Ÿè¿›è¡Œè½®æ¢
        perf_index = (user_id + request_count // 3) % len(self.performance_modes)
        performance_mode = self.performance_modes[perf_index]

        # é€‰æ‹©ç‰¹å®šçš„æŸ¥è¯¢æ–‡æœ¬
        available_queries = self.variable_length_queries[length_category]
        query_index = (user_id * 5 + request_count) % len(available_queries)
        query_text = available_queries[query_index]

        return {
            "query_mode": query_mode,
            "performance_mode": performance_mode,
            "length_category": length_category,
            "query_text": query_text,
            "estimated_tokens": self._estimate_tokens(query_text)
        }

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦æ•° + è‹±æ–‡å•è¯æ•°ï¼‰"""
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        english_words = len([w for w in text.split() if any(c.isalpha() for c in w)])
        return chinese_chars + english_words

    async def setup(self):
        """åˆå§‹åŒ–è®¾ç½® - é«˜å¹¶å‘ä¼˜åŒ–"""
        # åˆ›å»ºé«˜æ€§èƒ½è¿æ¥å™¨
        connector = aiohttp.TCPConnector(
            limit=self.config.connection_pool_size,
            limit_per_host=self.config.connection_per_host,
            ttl_dns_cache=300,
            use_dns_cache=True,
            enable_cleanup_closed=True,
            keepalive_timeout=30
        )

        timeout = aiohttp.ClientTimeout(total=self.config.request_timeout)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'Connection': 'keep-alive'}
        )

        # æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
        await self.check_service_availability()

        # é¢„çƒ­ç³»ç»Ÿ
        await self.warmup_system()

        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.performance_monitor.start_monitoring()

        logger.info(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¯åŠ¨ {self.config.concurrent_users} ä¸ªå¹¶å‘ç”¨æˆ·")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.performance_monitor.stop_monitoring()

        if self.session:
            await self.session.close()

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        logger.info("ğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")

    async def check_service_availability(self):
        """æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§"""
        try:
            async with self.session.get(f"{self.config.base_url}/health") as response:
                if response.status == 200:
                    logger.info("âœ… æœåŠ¡å¯ç”¨ï¼Œå¼€å§‹å‹åŠ›æµ‹è¯•")
                else:
                    raise Exception(f"æœåŠ¡ä¸å¯ç”¨ï¼ŒçŠ¶æ€ç : {response.status}")
        except Exception as e:
            logger.error(f"âŒ æœåŠ¡ä¸å¯ç”¨: {e}")
            raise

    async def warmup_system(self):
        """ç³»ç»Ÿé¢„çƒ­"""
        logger.info("ğŸ”¥ å¼€å§‹ç³»ç»Ÿé¢„çƒ­...")
        warmup_tasks = []

        # é¢„çƒ­å„ç§ç±»å‹çš„è¯·æ±‚
        for _ in range(10):
            question = random.choice(self.test_questions)
            warmup_tasks.append(self.test_qa_query(question, user_id=-1, is_warmup=True))

        for _ in range(5):
            warmup_tasks.append(self.test_intelligent_query(user_id=-1, request_count=0, is_warmup=True))

        for _ in range(3):
            warmup_tasks.append(self.test_qa_batch_query(user_id=-1, is_warmup=True))

        warmup_tasks.append(self.test_qa_health_check(user_id=-1, is_warmup=True))
        warmup_tasks.append(self.test_qa_statistics(user_id=-1, is_warmup=True))

        await asyncio.gather(*warmup_tasks, return_exceptions=True)
        logger.info("âœ… ç³»ç»Ÿé¢„çƒ­å®Œæˆ")

    def increment_request_counter(self):
        """çº¿ç¨‹å®‰å…¨çš„è¯·æ±‚è®¡æ•°å™¨"""
        with self.request_counter_lock:
            self.total_requests += 1

    async def test_qa_query(self, question: str, user_id: int, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•é—®ç­”æŸ¥è¯¢"""
        start_time = time.time()
        endpoint = "/api/v1/qa/query"

        payload = {
            "question": question,
            "top_k": random.randint(1, 5),
            "min_similarity": random.uniform(0.7, 0.98)
        }

        try:
            headers = self._build_user_headers(user_id)
            async with self.session.post(
                f"{self.config.base_url}{endpoint}",
                json=payload,
                headers=headers
            ) as response:
                response_time = time.time() - start_time
                return await self._handle_response_and_backoff(endpoint, response, response_time, user_id, 0, is_warmup)

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=endpoint,
                method="POST",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def test_intelligent_query(self, user_id: int, request_count: int = 0, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•æ™ºèƒ½æŸ¥è¯¢ï¼ˆä¸åŒæ¨¡å¼å’Œæ–‡æœ¬é•¿åº¦ï¼‰"""
        start_time = time.time()
        endpoint = "/api/v1/query"

        # è·å–ç”¨æˆ·ç‰¹å®šçš„æŸ¥è¯¢é…ç½®
        if is_warmup:
            # é¢„çƒ­æ—¶ä½¿ç”¨éšæœºé…ç½®
            query_mode = random.choice(self.query_modes)
            performance_mode = random.choice(self.performance_modes)
            length_category = random.choice(list(self.variable_length_queries.keys()))
            query_text = random.choice(self.variable_length_queries[length_category])
            estimated_tokens = self._estimate_tokens(query_text)
        else:
            # æ­£å¼æµ‹è¯•æ—¶ä½¿ç”¨ç¡®å®šæ€§é…ç½®ï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰æ¨¡å¼
            config = self.get_user_specific_query_config(user_id, request_count)
            query_mode = config["query_mode"]
            performance_mode = config["performance_mode"]
            length_category = config["length_category"]
            query_text = config["query_text"]
            estimated_tokens = config["estimated_tokens"]

        payload = {
            "query": query_text,
            "knowledge_base": "cs_college",  # æŒ‡å®šcs_collegeçŸ¥è¯†åº“
            "mode": query_mode,
            "performance_mode": performance_mode,
            "stream": False,
            "only_need_context": False
        }

        try:
            headers = self._build_user_headers(user_id, request_count=request_count)
            async with self.session.post(
                f"{self.config.base_url}{endpoint}",
                json=payload,
                headers=headers
            ) as response:
                response_time = time.time() - start_time
                return await self._handle_response_and_backoff(
                    f"{endpoint}_{query_mode}_{length_category}_{estimated_tokens}tokens",
                    response,
                    response_time,
                    user_id,
                    request_count,
                    is_warmup,
                )

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=f"{endpoint}_{query_mode}_{length_category}_{estimated_tokens}tokens",
                method="POST",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def test_qa_batch_query(self, user_id: int, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•æ‰¹é‡é—®ç­”æŸ¥è¯¢"""
        start_time = time.time()
        endpoint = "/api/v1/qa/query/batch"

        # éšæœºé€‰æ‹©2-5ä¸ªé—®é¢˜è¿›è¡Œæ‰¹é‡æŸ¥è¯¢
        questions = random.sample(self.test_questions, random.randint(2, 5))
        payload = {
            "questions": questions,
            "top_k": random.randint(1, 3),
            "min_similarity": random.uniform(0.7, 0.98)
        }

        try:
            headers = self._build_user_headers(user_id)
            async with self.session.post(
                f"{self.config.base_url}{endpoint}",
                json=payload,
                headers=headers
            ) as response:
                response_time = time.time() - start_time
                return await self._handle_response_and_backoff(endpoint, response, response_time, user_id, 0, is_warmup)

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=endpoint,
                method="POST",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def test_qa_create_pair(self, user_id: int, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•åˆ›å»ºé—®ç­”å¯¹"""
        start_time = time.time()
        endpoint = "/api/v1/qa/pairs"

        # éšæœºé€‰æ‹©ä¸€ä¸ªé—®ç­”å¯¹æ•°æ®å¹¶æ·»åŠ éšæœºåç¼€
        base_data = random.choice(self.qa_pairs_data).copy()
        timestamp = int(time.time() * 1000)
        base_data["question"] = f"{base_data['question']} (ç”¨æˆ·{user_id}-{timestamp})"
        base_data["answer"] = f"{base_data['answer']} (å‹æµ‹æ•°æ®-{timestamp})"

        try:
            headers = self._build_user_headers(user_id)
            async with self.session.post(
                f"{self.config.base_url}{endpoint}",
                json=base_data,
                headers=headers
            ) as response:
                response_time = time.time() - start_time
                return await self._handle_response_and_backoff(endpoint, response, response_time, user_id, 0, is_warmup)

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=endpoint,
                method="POST",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def test_qa_health_check(self, user_id: int, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•é—®ç­”ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        start_time = time.time()
        endpoint = "/api/v1/qa/health"

        try:
            async with self.session.get(f"{self.config.base_url}{endpoint}") as response:
                response_time = time.time() - start_time

                success = response.status == 200
                error_msg = None if success else f"HTTP {response.status}"

                result = TestResult(
                    endpoint=endpoint,
                    method="GET",
                    status_code=response.status,
                    response_time=response_time,
                    success=success,
                    error_message=error_msg,
                    user_id=user_id
                )

                if not is_warmup:
                    self.result_buffer.add_result(result)
                    self.increment_request_counter()

                return result

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=endpoint,
                method="GET",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def test_qa_statistics(self, user_id: int, is_warmup: bool = False) -> TestResult:
        """æµ‹è¯•é—®ç­”ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        start_time = time.time()
        endpoint = "/api/v1/qa/statistics"

        try:
            async with self.session.get(f"{self.config.base_url}{endpoint}") as response:
                response_time = time.time() - start_time

                success = response.status == 200
                error_msg = None if success else f"HTTP {response.status}"

                result = TestResult(
                    endpoint=endpoint,
                    method="GET",
                    status_code=response.status,
                    response_time=response_time,
                    success=success,
                    error_message=error_msg,
                    user_id=user_id
                )

                if not is_warmup:
                    self.result_buffer.add_result(result)
                    self.increment_request_counter()

                return result

        except Exception as e:
            response_time = time.time() - start_time
            result = TestResult(
                endpoint=endpoint,
                method="GET",
                status_code=0,
                response_time=response_time,
                success=False,
                error_message=str(e),
                user_id=user_id
            )

            if not is_warmup:
                self.result_buffer.add_result(result)
                self.increment_request_counter()

            return result

    async def user_simulation_task(self, user_id: int):
        """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·çš„æµ‹è¯•ä»»åŠ¡ - é«˜å¹¶å‘ä¼˜åŒ–"""
        logger.info(f"ğŸ‘¤ ç”¨æˆ· {user_id} å¼€å§‹æµ‹è¯•")
        self.active_users += 1

        request_count = 0
        last_gc_time = time.time()

        try:
            while time.time() - self.start_time < self.config.test_duration:
                try:
                    # æ ¹æ®é…ç½®çš„æ¯”ä¾‹é€‰æ‹©æµ‹è¯•ç±»å‹
                    rand = random.random()

                    if rand < self.config.query_ratio:
                        # æ™ºèƒ½æŸ¥è¯¢æµ‹è¯•ï¼ˆå„ç§æ¨¡å¼å’Œæ–‡æœ¬é•¿åº¦ï¼‰
                        await self.test_intelligent_query(user_id, request_count)

                    elif rand < self.config.query_ratio + self.config.qa_query_ratio:
                        # é—®ç­”æŸ¥è¯¢æµ‹è¯•
                        question = random.choice(self.test_questions)
                        await self.test_qa_query(question, user_id)

                    elif rand < (self.config.query_ratio + self.config.qa_query_ratio +
                                self.config.qa_batch_ratio):
                        # æ‰¹é‡æŸ¥è¯¢æµ‹è¯•
                        await self.test_qa_batch_query(user_id)

                    elif rand < (self.config.query_ratio + self.config.qa_query_ratio +
                                self.config.qa_batch_ratio + self.config.qa_create_ratio):
                        # åˆ›å»ºé—®ç­”å¯¹æµ‹è¯•
                        await self.test_qa_create_pair(user_id)

                    else:
                        # å¥åº·æ£€æŸ¥æµ‹è¯•
                        await self.test_qa_health_check(user_id)

                    request_count += 1

                    # å®šæœŸåƒåœ¾å›æ”¶
                    if request_count % self.config.gc_interval == 0:
                        current_time = time.time()
                        if current_time - last_gc_time > 60:  # æ¯åˆ†é’Ÿæœ€å¤šä¸€æ¬¡
                            gc.collect()
                            last_gc_time = current_time

                    # éšæœºç­‰å¾…æ—¶é—´ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
                    await asyncio.sleep(random.uniform(0.1, 1.5))

                except Exception as e:
                    logger.warning(f"ç”¨æˆ· {user_id} è¯·æ±‚å¼‚å¸¸: {e}")
                    await asyncio.sleep(1)

        except Exception as e:
            logger.error(f"ç”¨æˆ· {user_id} ä»»åŠ¡å¼‚å¸¸: {e}")
        finally:
            self.active_users -= 1
            logger.info(f"ğŸ‘¤ ç”¨æˆ· {user_id} æµ‹è¯•å®Œæˆï¼Œæ€»è¯·æ±‚æ•°: {request_count}")

    async def progress_reporter_task(self):
        """è¿›åº¦æŠ¥å‘Šä»»åŠ¡"""
        logger.info("ğŸ“ˆ å¼€å§‹è¿›åº¦ç›‘æ§")

        while time.time() - self.start_time < self.config.test_duration:
            elapsed_time = time.time() - self.start_time
            remaining_time = self.config.test_duration - elapsed_time
            progress_percent = (elapsed_time / self.config.test_duration) * 100

            buffer_stats = self.result_buffer.get_stats()

            logger.info(
                f"ğŸ“Š è¿›åº¦: {progress_percent:.1f}% | "
                f"æ´»è·ƒç”¨æˆ·: {self.active_users} | "
                f"æ€»è¯·æ±‚: {self.total_requests} | "
                f"å‰©ä½™æ—¶é—´: {remaining_time:.0f}s | "
                f"ç¼“å†²åŒº: {buffer_stats['buffer_size']}/{buffer_stats['max_size']}"
            )

            await asyncio.sleep(self.config.progress_report_interval)

        logger.info("ğŸ“ˆ è¿›åº¦ç›‘æ§å®Œæˆ")

    async def run_stress_test(self):
        """è¿è¡Œå‹åŠ›æµ‹è¯• - é«˜å¹¶å‘ä¼˜åŒ–"""
        logger.info(f"ğŸš€ å¼€å§‹é«˜å¹¶å‘å‹åŠ›æµ‹è¯• - {self.config.concurrent_users} å¹¶å‘ç”¨æˆ·")
        self.start_time = time.time()

        # åˆ›å»ºç”¨æˆ·æ¨¡æ‹Ÿä»»åŠ¡
        user_tasks = []

        # å¯åŠ¨è¿›åº¦æŠ¥å‘Šä»»åŠ¡
        progress_task = asyncio.create_task(self.progress_reporter_task())

        # é€æ­¥å¢åŠ è´Ÿè½½ (Ramp-up)
        ramp_up_interval = self.config.ramp_up_time / self.config.concurrent_users

        logger.info(f"ğŸ”„ å¼€å§‹è´Ÿè½½å¢åŠ é˜¶æ®µï¼Œ{self.config.ramp_up_time}ç§’å†…é€æ­¥å¯åŠ¨ç”¨æˆ·")

        for user_id in range(self.config.concurrent_users):
            # å»¶è¿Ÿå¯åŠ¨ç”¨æˆ·ï¼Œå®ç°é€æ­¥å¢åŠ è´Ÿè½½
            if user_id > 0:
                await asyncio.sleep(ramp_up_interval)

            task = asyncio.create_task(self.user_simulation_task(user_id))
            user_tasks.append(task)

            if (user_id + 1) % 100 == 0:  # æ¯100ä¸ªç”¨æˆ·æŠ¥å‘Šä¸€æ¬¡
                logger.info(f"ğŸ”„ å·²å¯åŠ¨ {user_id + 1}/{self.config.concurrent_users} ä¸ªç”¨æˆ·")

        logger.info(f"âœ… æ‰€æœ‰ {self.config.concurrent_users} ä¸ªç”¨æˆ·å·²å¯åŠ¨ï¼Œè¿›å…¥ç¨³å®šæµ‹è¯•é˜¶æ®µ")

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        all_tasks = user_tasks + [progress_task]
        await asyncio.gather(*all_tasks, return_exceptions=True)

        self.end_time = time.time()
        logger.info("âœ… å‹åŠ›æµ‹è¯•å®Œæˆ")

    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå…¨é¢çš„æµ‹è¯•æŠ¥å‘Š"""
        results = self.result_buffer.get_all_results()
        system_metrics = self.performance_monitor.get_all_metrics()

        if not results:
            return {"error": "æ²¡æœ‰æµ‹è¯•ç»“æœ"}

        # åŸºæœ¬ç»Ÿè®¡
        total_requests = len(results)
        successful_requests = sum(1 for r in results if r.success)
        failed_requests = total_requests - successful_requests
        success_rate = (successful_requests / total_requests) * 100 if total_requests > 0 else 0

        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [r.response_time for r in results]
        avg_response_time = statistics.mean(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)

        # è®¡ç®—ç™¾åˆ†ä½æ•°
        sorted_times = sorted(response_times)
        p50_response_time = statistics.median(sorted_times)
        p90_response_time = sorted_times[int(len(sorted_times) * 0.9)] if len(sorted_times) > 10 else max_response_time
        p95_response_time = sorted_times[int(len(sorted_times) * 0.95)] if len(sorted_times) > 20 else max_response_time
        p99_response_time = sorted_times[int(len(sorted_times) * 0.99)] if len(sorted_times) > 100 else max_response_time

        # æŒ‰ç«¯ç‚¹ç»Ÿè®¡
        endpoint_stats = defaultdict(lambda: {
            "total": 0, "success": 0, "failed": 0, "response_times": []
        })

        for result in results:
            endpoint = result.endpoint
            endpoint_stats[endpoint]["total"] += 1
            if result.success:
                endpoint_stats[endpoint]["success"] += 1
            else:
                endpoint_stats[endpoint]["failed"] += 1
            endpoint_stats[endpoint]["response_times"].append(result.response_time)

        # è®¡ç®—æ¯ä¸ªç«¯ç‚¹çš„ç»Ÿè®¡ä¿¡æ¯
        for endpoint, stats in endpoint_stats.items():
            times = stats["response_times"]
            if times:
                stats["avg_response_time"] = statistics.mean(times)
                stats["min_response_time"] = min(times)
                stats["max_response_time"] = max(times)
                stats["p95_response_time"] = sorted(times)[int(len(times) * 0.95)] if len(times) > 20 else max(times)
                stats["success_rate"] = (stats["success"] / stats["total"]) * 100
            del stats["response_times"]  # åˆ é™¤åŸå§‹æ•°æ®

        # ç³»ç»Ÿèµ„æºç»Ÿè®¡
        system_stats = {}
        if system_metrics:
            cpu_values = [m.cpu_percent for m in system_metrics]
            memory_values = [m.memory_percent for m in system_metrics]
            connection_values = [m.active_connections for m in system_metrics]

            system_stats = {
                "avg_cpu_percent": statistics.mean(cpu_values),
                "max_cpu_percent": max(cpu_values),
                "min_cpu_percent": min(cpu_values),
                "avg_memory_percent": statistics.mean(memory_values),
                "max_memory_percent": max(memory_values),
                "avg_memory_used_mb": statistics.mean([m.memory_used_mb for m in system_metrics]),
                "max_memory_used_mb": max([m.memory_used_mb for m in system_metrics]),
                "avg_active_connections": statistics.mean(connection_values),
                "max_active_connections": max(connection_values),
                "metrics_count": len(system_metrics)
            }

        # æ”¶é›†é”™è¯¯æ ·æœ¬ç»Ÿè®¡
        error_samples_summary = {k: v for k, v in self.error_samples.items()}

        # é”™è¯¯ç»Ÿè®¡
        error_stats = defaultdict(int)
        for result in results:
            if not result.success and result.error_message:
                error_stats[result.error_message] += 1

        # ç”¨æˆ·ç»Ÿè®¡
        user_stats = defaultdict(lambda: {"requests": 0, "success": 0, "failed": 0})
        for result in results:
            user_id = result.user_id
            user_stats[user_id]["requests"] += 1
            if result.success:
                user_stats[user_id]["success"] += 1
            else:
                user_stats[user_id]["failed"] += 1

        # æ—¶é—´åˆ†å¸ƒç»Ÿè®¡
        test_duration = self.end_time - self.start_time if self.end_time > 0 else 0
        requests_per_second = total_requests / test_duration if test_duration > 0 else 0

        # ç¼“å†²åŒºç»Ÿè®¡
        buffer_stats = self.result_buffer.get_stats()

        report = {
            "test_summary": {
                "test_duration_seconds": round(test_duration, 2),
                "total_requests": total_requests,
                "successful_requests": successful_requests,
                "failed_requests": failed_requests,
                "success_rate_percent": round(success_rate, 2),
                "requests_per_second": round(requests_per_second, 2),
                "concurrent_users": self.config.concurrent_users,
                "buffer_overflow_count": buffer_stats.get("overflow_count", 0)
            },
            "response_time_stats": {
                "average_ms": round(avg_response_time * 1000, 2),
                "minimum_ms": round(min_response_time * 1000, 2),
                "maximum_ms": round(max_response_time * 1000, 2),
                "p50_ms": round(p50_response_time * 1000, 2),
                "p90_ms": round(p90_response_time * 1000, 2),
                "p95_ms": round(p95_response_time * 1000, 2),
                "p99_ms": round(p99_response_time * 1000, 2)
            },
            "endpoint_statistics": dict(endpoint_stats),
            "system_resources": system_stats,
            "error_statistics": dict(error_stats),
            "error_samples": error_samples_summary,
            "user_statistics": {
                "total_users": len(user_stats),
                "avg_requests_per_user": round(total_requests / len(user_stats), 2) if user_stats else 0,
                "user_details": dict(user_stats) if len(user_stats) <= 50 else {}  # åªä¿å­˜å‰50ä¸ªç”¨æˆ·è¯¦æƒ…
            },
            "test_config": asdict(self.config),
            "timestamp": datetime.now().isoformat(),
            "test_environment": {
                "python_version": sys.version,
                "platform": sys.platform,
                "cpu_count": psutil.cpu_count(),
                "total_memory_gb": round(psutil.virtual_memory().total / (1024**3), 2)
            }
        }

        return report

    def save_comprehensive_report(self, report: Dict[str, Any], filename: str = None):
        """ä¿å­˜å…¨é¢çš„æµ‹è¯•æŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"tests/stress_test_report_{self.config.concurrent_users}users_{timestamp}.json"

        try:
            # ç¡®ä¿testsç›®å½•å­˜åœ¨
            os.makedirs("tests", exist_ok=True)

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            # åŒæ—¶ä¿å­˜ç®€åŒ–ç‰ˆæŠ¥å‘Š
            summary_filename = filename.replace('.json', '_summary.json')
            summary_report = {
                "test_summary": report["test_summary"],
                "response_time_stats": report["response_time_stats"],
                "endpoint_statistics": report["endpoint_statistics"],
                "system_resources": report["system_resources"],
                "timestamp": report["timestamp"]
            }

            with open(summary_filename, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, ensure_ascii=False, indent=2)

            logger.info(f"ğŸ“„ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {filename}")
            logger.info(f"ğŸ“„ ç®€åŒ–æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {summary_filename}")

            return filename, summary_filename

        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return None, None

    def print_comprehensive_summary(self, report: Dict[str, Any]):
        """æ‰“å°å…¨é¢çš„æµ‹è¯•æ‘˜è¦"""
        summary = report["test_summary"]
        response_stats = report["response_time_stats"]
        system_stats = report.get("system_resources", {})
        user_stats = report.get("user_statistics", {})

        print("\n" + "="*100)
        print("ğŸ¯ é«˜å¹¶å‘å‹åŠ›æµ‹è¯•ç»“æœæ‘˜è¦")
        print("="*100)

        print(f"ğŸ“Š æµ‹è¯•æ¦‚è§ˆ:")
        print(f"   â€¢ æµ‹è¯•æ—¶é•¿: {summary['test_duration_seconds']} ç§’")
        print(f"   â€¢ å¹¶å‘ç”¨æˆ·: {summary['concurrent_users']}")
        print(f"   â€¢ æ€»è¯·æ±‚æ•°: {summary['total_requests']}")
        print(f"   â€¢ æˆåŠŸè¯·æ±‚: {summary['successful_requests']}")
        print(f"   â€¢ å¤±è´¥è¯·æ±‚: {summary['failed_requests']}")
        print(f"   â€¢ æˆåŠŸç‡: {summary['success_rate_percent']}%")
        print(f"   â€¢ ååé‡: {summary['requests_per_second']} è¯·æ±‚/ç§’")
        if summary.get('buffer_overflow_count', 0) > 0:
            print(f"   âš ï¸  ç¼“å†²åŒºæº¢å‡º: {summary['buffer_overflow_count']} æ¬¡")

        print(f"\nâ±ï¸  å“åº”æ—¶é—´ç»Ÿè®¡:")
        print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {response_stats['average_ms']} ms")
        print(f"   â€¢ æœ€å°å“åº”æ—¶é—´: {response_stats['minimum_ms']} ms")
        print(f"   â€¢ æœ€å¤§å“åº”æ—¶é—´: {response_stats['maximum_ms']} ms")
        print(f"   â€¢ P50å“åº”æ—¶é—´: {response_stats['p50_ms']} ms")
        print(f"   â€¢ P90å“åº”æ—¶é—´: {response_stats['p90_ms']} ms")
        print(f"   â€¢ P95å“åº”æ—¶é—´: {response_stats['p95_ms']} ms")
        print(f"   â€¢ P99å“åº”æ—¶é—´: {response_stats['p99_ms']} ms")

        if system_stats:
            print(f"\nğŸ’» ç³»ç»Ÿèµ„æºä½¿ç”¨:")
            print(f"   â€¢ CPUä½¿ç”¨ç‡: å¹³å‡ {system_stats.get('avg_cpu_percent', 0):.1f}% | "
                  f"æœ€å¤§ {system_stats.get('max_cpu_percent', 0):.1f}%")
            print(f"   â€¢ å†…å­˜ä½¿ç”¨ç‡: å¹³å‡ {system_stats.get('avg_memory_percent', 0):.1f}% | "
                  f"æœ€å¤§ {system_stats.get('max_memory_percent', 0):.1f}%")
            print(f"   â€¢ å†…å­˜ä½¿ç”¨é‡: æœ€å¤§ {system_stats.get('max_memory_used_mb', 0):.1f} MB")
            print(f"   â€¢ æ´»è·ƒè¿æ¥æ•°: å¹³å‡ {system_stats.get('avg_active_connections', 0):.0f} | "
                  f"æœ€å¤§ {system_stats.get('max_active_connections', 0)}")

        print(f"\nğŸ‘¥ ç”¨æˆ·ç»Ÿè®¡:")
        print(f"   â€¢ å‚ä¸ç”¨æˆ·æ•°: {user_stats.get('total_users', 0)}")
        print(f"   â€¢ å¹³å‡æ¯ç”¨æˆ·è¯·æ±‚æ•°: {user_stats.get('avg_requests_per_user', 0)}")

        print(f"\nğŸ” ç«¯ç‚¹æ€§èƒ½è¯¦æƒ…:")
        query_mode_stats = defaultdict(lambda: {"total": 0, "success": 0, "response_times": []})
        text_length_stats = defaultdict(lambda: {"total": 0, "success": 0, "response_times": []})
        token_range_stats = defaultdict(lambda: {"total": 0, "success": 0, "response_times": []})

        for endpoint, stats in report["endpoint_statistics"].items():
            print(f"   â€¢ {endpoint}:")
            print(f"     - è¯·æ±‚æ•°: {stats['total']} | æˆåŠŸç‡: {stats['success_rate']:.1f}%")
            print(f"     - å“åº”æ—¶é—´: å¹³å‡ {stats['avg_response_time']*1000:.1f}ms | "
                  f"P95 {stats.get('p95_response_time', 0)*1000:.1f}ms")

            # è§£æç«¯ç‚¹ä¿¡æ¯ï¼š/api/v1/query_mode_length_tokenstokens
            if "/api/v1/query_" in endpoint:
                parts = endpoint.split("_")
                if len(parts) >= 4:
                    mode = parts[2]
                    length = parts[3]

                    # æå–tokenæ•°é‡
                    tokens_str = parts[4] if len(parts) > 4 else "0tokens"
                    tokens = int(tokens_str.replace("tokens", "")) if tokens_str.replace("tokens", "").isdigit() else 0

                    # æŒ‰tokenèŒƒå›´åˆ†ç±»
                    if tokens <= 200:
                        token_range = "50-200"
                    elif tokens <= 800:
                        token_range = "200-800"
                    elif tokens <= 2000:
                        token_range = "800-2000"
                    elif tokens <= 5000:
                        token_range = "2000-5000"
                    else:
                        token_range = "5000-8000"

                    # ç»Ÿè®¡æŸ¥è¯¢æ¨¡å¼
                    query_mode_stats[mode]["total"] += stats['total']
                    query_mode_stats[mode]["success"] += stats['success']
                    query_mode_stats[mode]["response_times"].append(stats['avg_response_time'])

                    # ç»Ÿè®¡æ–‡æœ¬é•¿åº¦ç±»åˆ«
                    text_length_stats[length]["total"] += stats['total']
                    text_length_stats[length]["success"] += stats['success']
                    text_length_stats[length]["response_times"].append(stats['avg_response_time'])

                    # ç»Ÿè®¡tokenèŒƒå›´
                    token_range_stats[token_range]["total"] += stats['total']
                    token_range_stats[token_range]["success"] += stats['success']
                    token_range_stats[token_range]["response_times"].append(stats['avg_response_time'])

        # æ˜¾ç¤ºæŸ¥è¯¢æ¨¡å¼ç»Ÿè®¡
        if query_mode_stats:
            print(f"\nğŸ“Š æŸ¥è¯¢æ¨¡å¼æ€§èƒ½ç»Ÿè®¡ (cs_collegeçŸ¥è¯†åº“):")
            for mode in ["local", "global", "hybrid", "naive", "mix", "bypass"]:
                if mode in query_mode_stats:
                    stats = query_mode_stats[mode]
                    success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
                    avg_time = statistics.mean(stats['response_times']) * 1000 if stats['response_times'] else 0
                    print(f"   â€¢ {mode:8}æ¨¡å¼: {stats['total']:4}æ¬¡ | æˆåŠŸç‡: {success_rate:5.1f}% | å¹³å‡å“åº”: {avg_time:6.1f}ms")

        # æ˜¾ç¤ºæ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        if text_length_stats:
            print(f"\nğŸ“ æ–‡æœ¬é•¿åº¦ç±»åˆ«æ€§èƒ½ç»Ÿè®¡:")
            length_order = ["short", "medium", "long", "very_long", "ultra_long"]
            for length in length_order:
                if length in text_length_stats:
                    stats = text_length_stats[length]
                    success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
                    avg_time = statistics.mean(stats['response_times']) * 1000 if stats['response_times'] else 0
                    print(f"   â€¢ {length:10}: {stats['total']:4}æ¬¡ | æˆåŠŸç‡: {success_rate:5.1f}% | å¹³å‡å“åº”: {avg_time:6.1f}ms")

        # æ˜¾ç¤ºtokenèŒƒå›´ç»Ÿè®¡
        if token_range_stats:
            print(f"\nğŸ¯ TokenèŒƒå›´æ€§èƒ½ç»Ÿè®¡:")
            token_ranges = ["50-200", "200-800", "800-2000", "2000-5000", "5000-8000"]
            for token_range in token_ranges:
                if token_range in token_range_stats:
                    stats = token_range_stats[token_range]
                    success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
                    avg_time = statistics.mean(stats['response_times']) * 1000 if stats['response_times'] else 0
                    print(f"   â€¢ {token_range:10} tokens: {stats['total']:4}æ¬¡ | æˆåŠŸç‡: {success_rate:5.1f}% | å¹³å‡å“åº”: {avg_time:6.1f}ms")

        if report["error_statistics"]:
            print(f"\nâŒ é”™è¯¯ç»Ÿè®¡:")
            for error, count in list(report["error_statistics"].items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"   â€¢ {error}: {count} æ¬¡")
            if len(report["error_statistics"]) > 10:
                print(f"   â€¢ ... è¿˜æœ‰ {len(report['error_statistics']) - 10} ç§å…¶ä»–é”™è¯¯")

        # æ€§èƒ½è¯„ä¼°
        print(f"\nğŸ† æ€§èƒ½è¯„ä¼°:")
        avg_response = response_stats['average_ms']
        p95_response = response_stats['p95_ms']
        success_rate = summary['success_rate_percent']

        if success_rate >= 99.5 and avg_response <= 500 and p95_response <= 1000:
            print("   âœ… ä¼˜ç§€ - ç³»ç»Ÿåœ¨é«˜å¹¶å‘ä¸‹è¡¨ç°å‡ºè‰²")
        elif success_rate >= 99 and avg_response <= 1000 and p95_response <= 2000:
            print("   âœ… è‰¯å¥½ - ç³»ç»Ÿæ€§èƒ½æ»¡è¶³è¦æ±‚")
        elif success_rate >= 95 and avg_response <= 2000:
            print("   âš ï¸  ä¸€èˆ¬ - ç³»ç»Ÿæ€§èƒ½æœ‰å¾…ä¼˜åŒ–")
        else:
            print("   âŒ éœ€è¦ä¼˜åŒ– - ç³»ç»Ÿåœ¨é«˜å¹¶å‘ä¸‹å­˜åœ¨æ€§èƒ½é—®é¢˜")

        print("\n" + "="*100)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="GuiXiaoXiRag é«˜å¹¶å‘å‹åŠ›æµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€æµ‹è¯• (100ç”¨æˆ·, 10åˆ†é’Ÿ, 70%æ™ºèƒ½æŸ¥è¯¢)
  python tests/stress_test.py

  # é«˜å¹¶å‘æµ‹è¯• (1000ç”¨æˆ·, 30åˆ†é’Ÿ, cs_collegeçŸ¥è¯†åº“)
  python tests/stress_test.py --users 1000 --duration 1800

  # æé™æµ‹è¯• (2000ç”¨æˆ·, 1å°æ—¶, è‡ªå®šä¹‰æŸ¥è¯¢æ¯”ä¾‹)
  python tests/stress_test.py --users 2000 --duration 3600 --query-ratio 0.8

  # ä¸“é¡¹æ™ºèƒ½æŸ¥è¯¢æµ‹è¯• (500ç”¨æˆ·, 15åˆ†é’Ÿ, 90%æ™ºèƒ½æŸ¥è¯¢)
  python tests/stress_test.py --users 500 --duration 900 --query-ratio 0.9 --qa-query-ratio 0.05
        """
    )

    parser.add_argument("--url", default="http://localhost:8002", help="æœåŠ¡å™¨URL (é»˜è®¤: http://localhost:8002)")
    parser.add_argument("--users", type=int, default=100, help="å¹¶å‘ç”¨æˆ·æ•° (é»˜è®¤: 100)")
    parser.add_argument("--duration", type=int, default=600, help="æµ‹è¯•æŒç»­æ—¶é—´(ç§’) (é»˜è®¤: 600)")
    parser.add_argument("--ramp-up", type=int, default=60, help="è´Ÿè½½å¢åŠ æ—¶é—´(ç§’) (é»˜è®¤: 60)")
    parser.add_argument("--ramp-down", type=int, default=30, help="è´Ÿè½½å‡å°‘æ—¶é—´(ç§’) (é»˜è®¤: 30)")

    # æµ‹è¯•æ¯”ä¾‹é…ç½®
    parser.add_argument("--query-ratio", type=float, default=0.70, help="æ™ºèƒ½æŸ¥è¯¢æ¯”ä¾‹ (é»˜è®¤: 0.70)")
    parser.add_argument("--qa-query-ratio", type=float, default=0.15, help="é—®ç­”æŸ¥è¯¢æ¯”ä¾‹ (é»˜è®¤: 0.15)")
    parser.add_argument("--qa-batch-ratio", type=float, default=0.05, help="æ‰¹é‡æŸ¥è¯¢æ¯”ä¾‹ (é»˜è®¤: 0.05)")
    parser.add_argument("--qa-create-ratio", type=float, default=0.05, help="åˆ›å»ºé—®ç­”å¯¹æ¯”ä¾‹ (é»˜è®¤: 0.05)")

    # æ€§èƒ½é…ç½®
    parser.add_argument("--pool-size", type=int, default=500, help="è¿æ¥æ± å¤§å° (é»˜è®¤: 500)")
    parser.add_argument("--per-host", type=int, default=100, help="æ¯ä¸»æœºæœ€å¤§è¿æ¥æ•° limit_per_host (é»˜è®¤: 100)")
    parser.add_argument("--timeout", type=int, default=30, help="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 30)")
    parser.add_argument("--buffer-size", type=int, default=10000, help="ç»“æœç¼“å†²åŒºå¤§å° (é»˜è®¤: 10000)")

    # ç”¨æˆ·ä¸é™æµæ¨¡æ‹Ÿé…ç½®
    parser.add_argument("--min-interval-per-user", type=float, default=0.0, help="å•ç”¨æˆ·æœ€å°è¯·æ±‚é—´éš”ç§’ï¼Œç”¨äºé¿å…åŒä¸€ç”¨æˆ·é¢‘ç¹æŸ¥è¯¢")
    parser.add_argument("--spoof-client-ip", action="store_true", help="ä¸ºæ¯ä¸ªè™šæ‹Ÿç”¨æˆ·è®¾ç½®ä¸åŒçš„å®¢æˆ·ç«¯IPå¤´ä»¥ç»•è¿‡IPçº§é™æµ")
    parser.add_argument("--user-tier", type=str, default="default", help="ä¸ºæ‰€æœ‰è™šæ‹Ÿç”¨æˆ·è®¾ç½® X-User-Tierï¼ˆdefault/free/pro/enterpriseï¼‰")
    parser.add_argument("--error-sample-limit", type=int, default=50, help="æ¯ç±»é”™è¯¯é‡‡æ ·æ¡æ•°ä¸Šé™")
    parser.add_argument("--error-sample-size", type=int, default=500, help="æ¯æ¡é”™è¯¯æ ·æœ¬æœ€å¤§å­—ç¬¦æ•°")

    # ç›‘æ§ä¸åƒåœ¾å›æ”¶é…ç½®
    parser.add_argument("--metrics-interval", type=int, default=5, help="ç³»ç»ŸæŒ‡æ ‡é‡‡é›†é—´éš”ç§’ (é»˜è®¤: 5)")
    parser.add_argument("--progress-interval", type=int, default=30, help="è¿›åº¦æŠ¥å‘Šé—´éš”ç§’ (é»˜è®¤: 30)")
    parser.add_argument("--gc-interval", type=int, default=100, help="è§¦å‘åƒåœ¾å›æ”¶çš„è¯·æ±‚è®¡æ•°é—´éš” (é»˜è®¤: 100)")

    # è¾“å‡ºé…ç½®
    parser.add_argument("--output", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶åå‰ç¼€")
    parser.add_argument("--quiet", action="store_true", help="é™é»˜æ¨¡å¼ï¼Œå‡å°‘è¾“å‡º")

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if args.users > 2000:
        logger.warning("âš ï¸  ç”¨æˆ·æ•°è¶…è¿‡2000ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿèµ„æºå……è¶³")

    ratio_sum = args.query_ratio + args.qa_query_ratio + args.qa_batch_ratio + args.qa_create_ratio
    if abs(ratio_sum - 1.0) > 0.05:  # å…è®¸5%çš„è¯¯å·®ï¼Œå…¶ä½™ä¸ºå¥åº·æ£€æŸ¥
        logger.warning(f"âš ï¸  æµ‹è¯•æ¯”ä¾‹æ€»å’Œä¸º {ratio_sum:.2f}ï¼Œå»ºè®®è°ƒæ•´ä¸ºæ¥è¿‘1.0")

    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig(
        base_url=args.url,
        concurrent_users=args.users,
        test_duration=args.duration,
        ramp_up_time=args.ramp_up,
        ramp_down_time=args.ramp_down,
        query_ratio=args.query_ratio,
        qa_query_ratio=args.qa_query_ratio,
        qa_batch_ratio=args.qa_batch_ratio,
        qa_create_ratio=args.qa_create_ratio,
        health_ratio=0.05,
        connection_pool_size=args.pool_size,
        connection_per_host=args.per_host,
        request_timeout=args.timeout,
        result_buffer_size=args.buffer_size,
        # ç”¨æˆ·ä¸é™æµ
        min_interval_per_user=args.min_interval_per_user,
        spoof_client_ip=args.spoof_client_ip,
        user_tier=args.user_tier,
        # é”™è¯¯æ ·æœ¬
        error_sample_limit=args.error_sample_limit,
        error_sample_size=args.error_sample_size,
        # ç›‘æ§
        metrics_interval=args.metrics_interval,
        progress_report_interval=args.progress_interval,
        gc_interval=args.gc_interval
    )

    if not args.quiet:
        logger.info(f"ğŸš€ å‡†å¤‡å¯åŠ¨é«˜å¹¶å‘å‹åŠ›æµ‹è¯•")
        logger.info(f"ğŸ“Š é…ç½®: {args.users}ç”¨æˆ· | {args.duration}ç§’ | {args.url}")

    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    test_runner = HighConcurrencyStressTest(config)

    try:
        # åˆå§‹åŒ–
        await test_runner.setup()

        # è¿è¡Œå‹åŠ›æµ‹è¯•
        await test_runner.run_stress_test()

        # ç”ŸæˆæŠ¥å‘Š
        report = test_runner.generate_comprehensive_report()

        # ä¿å­˜æŠ¥å‘Š
        detail_file, summary_file = test_runner.save_comprehensive_report(report, args.output)

        # æ‰“å°æ‘˜è¦
        if not args.quiet:
            test_runner.print_comprehensive_summary(report)

        logger.info("ğŸ‰ å‹åŠ›æµ‹è¯•å®Œæˆï¼")
        if detail_file:
            logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {detail_file}")
        if summary_file:
            logger.info(f"ğŸ“„ ç®€åŒ–æŠ¥å‘Š: {summary_file}")

    except KeyboardInterrupt:
        logger.info("âš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        # æ¸…ç†èµ„æº
        await test_runner.cleanup()


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ (Windowså…¼å®¹æ€§)
    if sys.platform == 'win32':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    asyncio.run(main())
