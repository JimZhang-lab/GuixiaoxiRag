# GuiXiaoXiRag FastAPI æœåŠ¡

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**GuiXiaoXiæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰FastAPI æœåŠ¡**

*æä¾›ä¼ä¸šçº§çš„æ™ºèƒ½é—®ç­”å’ŒçŸ¥è¯†ç®¡ç†è§£å†³æ–¹æ¡ˆ*

[ğŸ“– æ–‡æ¡£](docs/README.md) â€¢ [ğŸš€ å¿«é€Ÿå¼€å§‹](docs/Quick_Start_Guide.md) â€¢ [ğŸŒ API æ–‡æ¡£](http://localhost:8002/docs)

</div>

## é¡¹ç›®ç®€ä»‹

GuiXiaoXiRag æ˜¯ä¸€ä¸ªåŸºäº FastAPI çš„æ™ºèƒ½çŸ¥è¯†é—®ç­”ç³»ç»Ÿï¼Œé›†æˆäº†çŸ¥è¯†å›¾è°±ã€å‘é‡æ£€ç´¢ã€æ„å›¾è¯†åˆ«ç­‰å¤šç§AIæŠ€æœ¯ã€‚è¯¥ç³»ç»Ÿæä¾›å¼ºå¤§çš„çŸ¥è¯†ç®¡ç†å’Œæ™ºèƒ½æŸ¥è¯¢åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„å¤„ç†å’Œå¤šæ¨¡æ€çš„çŸ¥è¯†æ£€ç´¢ã€‚

## ä¸»è¦ç‰¹æ€§

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½
- **æ™ºèƒ½æŸ¥è¯¢**: æ”¯æŒå¤šç§æŸ¥è¯¢æ¨¡å¼ï¼ˆlocal/global/hybrid/naive/mix/bypassï¼‰
- **çŸ¥è¯†å›¾è°±**: è‡ªåŠ¨æ„å»ºå’Œç®¡ç†çŸ¥è¯†å›¾è°±ï¼Œæ”¯æŒå¯è§†åŒ–å±•ç¤º
- **æ–‡æ¡£ç®¡ç†**: æ”¯æŒå¤šç§æ ¼å¼æ–‡æ¡£çš„ä¸Šä¼ ã€å¤„ç†å’Œç´¢å¼•
- **æ„å›¾è¯†åˆ«**: æ™ºèƒ½åˆ†ææŸ¥è¯¢æ„å›¾å’Œå®‰å…¨çº§åˆ«
- **å¤šçŸ¥è¯†åº“**: æ”¯æŒåˆ›å»ºå’Œç®¡ç†å¤šä¸ªç‹¬ç«‹çš„çŸ¥è¯†åº“

### ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§
- **æ¨¡å—åŒ–æ¶æ„**: æ¸…æ™°çš„åˆ†å±‚è®¾è®¡ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- **å¼‚æ­¥å¤„ç†**: åŸºäº FastAPI çš„é«˜æ€§èƒ½å¼‚æ­¥å¤„ç†
- **ç¼“å­˜æœºåˆ¶**: å¤šå±‚ç¼“å­˜ä¼˜åŒ–ï¼Œæå‡æŸ¥è¯¢æ€§èƒ½
- **å®‰å…¨æ£€æŸ¥**: å†…ç½®å®‰å…¨æ£€æŸ¥å’Œå†…å®¹è¿‡æ»¤æœºåˆ¶
- **æ€§èƒ½ç›‘æ§**: å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡å’Œå¥åº·æ£€æŸ¥

### ğŸ“Š æ”¯æŒæ ¼å¼
- **æ–‡æ¡£æ ¼å¼**: PDF, DOCX, DOC, TXT, MD, JSON, XML, CSV
- **æŸ¥è¯¢æ¨¡å¼**: æ–‡æœ¬æŸ¥è¯¢ã€æ‰¹é‡æŸ¥è¯¢ã€æµå¼æŸ¥è¯¢
- **è¾“å‡ºæ ¼å¼**: JSON, XML, CSV, HTMLå¯è§†åŒ–

## ç³»ç»Ÿæ¶æ„

```
GuiXiaoXiRag/
â”œâ”€â”€ api/                    # APIä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”œâ”€â”€ query_api.py       # æŸ¥è¯¢APIå¤„ç†å™¨
â”‚   â”œâ”€â”€ document_api.py    # æ–‡æ¡£ç®¡ç†API
â”‚   â”œâ”€â”€ knowledge_base_api.py  # çŸ¥è¯†åº“ç®¡ç†API
â”‚   â”œâ”€â”€ knowledge_graph_api.py # çŸ¥è¯†å›¾è°±API
â”‚   â”œâ”€â”€ system_api.py      # ç³»ç»Ÿç®¡ç†API
â”‚   â”œâ”€â”€ intent_recogition_api.py # æ„å›¾è¯†åˆ«API
â”‚   â””â”€â”€ cache_management_api.py  # ç¼“å­˜ç®¡ç†API
â”œâ”€â”€ routers/               # FastAPIè·¯ç”±å±‚
â”‚   â”œâ”€â”€ query_router.py    # æŸ¥è¯¢è·¯ç”±
â”‚   â”œâ”€â”€ document_router.py # æ–‡æ¡£ç®¡ç†è·¯ç”±
â”‚   â”œâ”€â”€ knowledge_base_router.py # çŸ¥è¯†åº“è·¯ç”±
â”‚   â”œâ”€â”€ knowledge_graph_router.py # çŸ¥è¯†å›¾è°±è·¯ç”±
â”‚   â”œâ”€â”€ system_router.py   # ç³»ç»Ÿç®¡ç†è·¯ç”±
â”‚   â”œâ”€â”€ intent_recogition_router.py # æ„å›¾è¯†åˆ«è·¯ç”±
â”‚   â””â”€â”€ cache_management_router.py  # ç¼“å­˜ç®¡ç†è·¯ç”±
â”œâ”€â”€ model/                 # æ•°æ®æ¨¡å‹å±‚
â”‚   â”œâ”€â”€ base_models.py     # åŸºç¡€æ¨¡å‹
â”‚   â”œâ”€â”€ request_models.py  # è¯·æ±‚æ¨¡å‹
â”‚   â”œâ”€â”€ response_models.py # å“åº”æ¨¡å‹
â”‚   â””â”€â”€ ...
â”œâ”€â”€ handler/               # æ ¸å¿ƒå¤„ç†å™¨
â”‚   â”œâ”€â”€ guixiaoxirag_service.py # æ ¸å¿ƒæœåŠ¡
â”‚   â”œâ”€â”€ document_processor.py   # æ–‡æ¡£å¤„ç†å™¨
â”‚   â”œâ”€â”€ knowledge_base_manager.py # çŸ¥è¯†åº“ç®¡ç†å™¨
â”‚   â””â”€â”€ query_processor.py      # æŸ¥è¯¢å¤„ç†å™¨
â”œâ”€â”€ core/                  # æ ¸å¿ƒç®—æ³•
â”‚   â”œâ”€â”€ rag/              # RAGç›¸å…³ç®—æ³•
â”‚   â”œâ”€â”€ intent_recognition/ # æ„å›¾è¯†åˆ«
â”‚   â””â”€â”€ quick_qa_base/    # å¿«é€Ÿé—®ç­”åŸºç¡€
â”œâ”€â”€ common/                # å…¬å…±ç»„ä»¶
â”‚   â”œâ”€â”€ config.py         # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ utils.py          # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ logging_utils.py  # æ—¥å¿—å·¥å…·
â”‚   â””â”€â”€ constants.py      # å¸¸é‡å®šä¹‰
â”œâ”€â”€ middleware/            # ä¸­é—´ä»¶
â”‚   â”œâ”€â”€ cors_middleware.py # CORSä¸­é—´ä»¶
â”‚   â”œâ”€â”€ logging_middleware.py # æ—¥å¿—ä¸­é—´ä»¶
â”‚   â””â”€â”€ security_middleware.py # å®‰å…¨ä¸­é—´ä»¶
â”œâ”€â”€ initialize/            # åˆå§‹åŒ–æ¨¡å—
â”œâ”€â”€ knowledgeBase/         # çŸ¥è¯†åº“å­˜å‚¨
â”œâ”€â”€ docs/                  # æ–‡æ¡£ç›®å½•
â”œâ”€â”€ tests/                 # æµ‹è¯•ç›®å½•
â””â”€â”€ main.py               # åº”ç”¨å…¥å£
```

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- å†…å­˜: 4GB+ (æ¨è 8GB+)
- ç£ç›˜ç©ºé—´: 10GB+
- æ“ä½œç³»ç»Ÿ: Windows/Linux/macOS

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone <repository-url>
cd server_new
```

2. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

3. **é…ç½®ç¯å¢ƒ**
```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
nano .env
```

4. **å¯åŠ¨æœåŠ¡**
```bash
python main.py
```

5. **éªŒè¯å®‰è£…**
```bash
# è®¿é—®å¥åº·æ£€æŸ¥ç«¯ç‚¹
curl http://localhost:8002/api/v1/health

# æˆ–åœ¨æµè§ˆå™¨ä¸­è®¿é—®
http://localhost:8002/docs
```

### é…ç½®è¯´æ˜

ä¸»è¦é…ç½®é¡¹ï¼ˆåœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½®ï¼‰ï¼š

```bash
# åº”ç”¨é…ç½®
APP_NAME="GuiXiaoXiRag FastAPI Service"
APP_VERSION="2.0.0"
HOST="0.0.0.0"
PORT=8002
DEBUG=false

# LLMé…ç½®
OPENAI_API_BASE="http://localhost:8100/v1"
OPENAI_CHAT_API_KEY="your_api_key_here"
OPENAI_CHAT_MODEL="qwen14b"

# Embeddingé…ç½®
OPENAI_EMBEDDING_API_BASE="http://localhost:8200/v1"
OPENAI_EMBEDDING_API_KEY="your_api_key_here"
OPENAI_EMBEDDING_MODEL="embedding_qwen"

# çŸ¥è¯†åº“é…ç½®
WORKING_DIR="./knowledgeBase/default"
MAX_FILE_SIZE=52428800  # 50MB

# æ—¥å¿—é…ç½®
LOG_LEVEL="INFO"
LOG_DIR="./logs"
```

## ä½¿ç”¨æŒ‡å—

### åŸºç¡€æŸ¥è¯¢

```python
import requests

# æ™ºèƒ½æŸ¥è¯¢
response = requests.post("http://localhost:8002/api/v1/query", json={
    "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "mode": "hybrid",
    "top_k": 10
})

print(response.json())
```

### æ–‡æ¡£ä¸Šä¼ 

```python
# ä¸Šä¼ æ–‡æ¡£
with open("document.pdf", "rb") as f:
    files = {"file": f}
    data = {"knowledge_base": "my_kb"}
    response = requests.post(
        "http://localhost:8002/api/v1/insert/file", 
        files=files, 
        data=data
    )
```

### çŸ¥è¯†åº“ç®¡ç†

```python
# åˆ›å»ºçŸ¥è¯†åº“
response = requests.post("http://localhost:8002/api/v1/knowledge-bases", json={
    "name": "ai_research",
    "description": "äººå·¥æ™ºèƒ½ç ”ç©¶çŸ¥è¯†åº“",
    "language": "ä¸­æ–‡"
})

# åˆ‡æ¢çŸ¥è¯†åº“
response = requests.post("http://localhost:8002/api/v1/knowledge-bases/switch", json={
    "name": "ai_research"
})
```

### çŸ¥è¯†å›¾è°±æŸ¥è¯¢

```python
# è·å–çŸ¥è¯†å›¾è°±æ•°æ®
response = requests.post("http://localhost:8002/api/v1/knowledge-graph", json={
    "node_label": "äººå·¥æ™ºèƒ½",
    "max_depth": 3,
    "max_nodes": 100
})
```

## API æ–‡æ¡£

### åœ¨çº¿æ–‡æ¡£
- Swagger UI: http://localhost:8002/docs
- ReDoc: http://localhost:8002/redoc

### è¯¦ç»†æ–‡æ¡£
- [å®Œæ•´APIæ–‡æ¡£](docs/API_Documentation.md)
- [æµ‹è¯•ç¤ºä¾‹](docs/API_Testing_Examples.md)

### ä¸»è¦ç«¯ç‚¹

| åˆ†ç±» | ç«¯ç‚¹ | æ–¹æ³• | æè¿° |
|------|------|------|------|
| ç³»ç»Ÿ | `/api/v1/health` | GET | å¥åº·æ£€æŸ¥ |
| ç³»ç»Ÿ | `/api/v1/system/status` | GET | ç³»ç»ŸçŠ¶æ€ |
| æŸ¥è¯¢ | `/api/v1/query` | POST | æ™ºèƒ½æŸ¥è¯¢ |
| æŸ¥è¯¢ | `/api/v1/query/batch` | POST | æ‰¹é‡æŸ¥è¯¢ |
| æ–‡æ¡£ | `/api/v1/insert/text` | POST | æ’å…¥æ–‡æœ¬ |
| æ–‡æ¡£ | `/api/v1/insert/file` | POST | ä¸Šä¼ æ–‡ä»¶ |
| çŸ¥è¯†åº“ | `/api/v1/knowledge-bases` | GET | çŸ¥è¯†åº“åˆ—è¡¨ |
| çŸ¥è¯†åº“ | `/api/v1/knowledge-bases` | POST | åˆ›å»ºçŸ¥è¯†åº“ |
| å›¾è°± | `/api/v1/knowledge-graph` | POST | è·å–å›¾è°±æ•°æ® |
| å›¾è°± | `/api/v1/knowledge-graph/stats` | GET | å›¾è°±ç»Ÿè®¡ |

## å¼€å‘æŒ‡å—

### é¡¹ç›®ç»“æ„è¯´æ˜

- **api/**: ä¸šåŠ¡é€»è¾‘å¤„ç†å±‚ï¼ŒåŒ…å«å„åŠŸèƒ½æ¨¡å—çš„APIå¤„ç†å™¨
- **routers/**: FastAPIè·¯ç”±å®šä¹‰ï¼Œè´Ÿè´£è¯·æ±‚è·¯ç”±å’Œå‚æ•°éªŒè¯
- **model/**: æ•°æ®æ¨¡å‹å®šä¹‰ï¼ŒåŒ…æ‹¬è¯·æ±‚/å“åº”æ¨¡å‹å’ŒåŸºç¡€æ¨¡å‹
- **handler/**: æ ¸å¿ƒä¸šåŠ¡å¤„ç†å™¨ï¼Œå®ç°å…·ä½“çš„ä¸šåŠ¡é€»è¾‘
- **core/**: æ ¸å¿ƒç®—æ³•å®ç°ï¼ŒåŒ…æ‹¬RAGã€æ„å›¾è¯†åˆ«ç­‰
- **common/**: å…¬å…±ç»„ä»¶ï¼ŒåŒ…æ‹¬é…ç½®ã€å·¥å…·ã€å¸¸é‡ç­‰
- **middleware/**: ä¸­é—´ä»¶ï¼Œå¤„ç†è·¨åˆ‡é¢å…³æ³¨ç‚¹

### æ·»åŠ æ–°åŠŸèƒ½

1. **å®šä¹‰æ•°æ®æ¨¡å‹** (model/)
2. **å®ç°ä¸šåŠ¡é€»è¾‘** (api/)
3. **æ·»åŠ è·¯ç”±å®šä¹‰** (routers/)
4. **æ³¨å†Œè·¯ç”±** (main.py)
5. **ç¼–å†™æµ‹è¯•** (tests/)

### ä»£ç è§„èŒƒ

- éµå¾ª PEP 8 ä»£ç é£æ ¼
- ä½¿ç”¨ç±»å‹æ³¨è§£
- ç¼–å†™å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†
- ç¼–å†™å•å…ƒæµ‹è¯•

## éƒ¨ç½²æŒ‡å—

### Docker éƒ¨ç½²

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8002

CMD ["python", "main.py"]
```

```bash
# æ„å»ºé•œåƒ
docker build -t guixiaoxirag .

# è¿è¡Œå®¹å™¨
docker run -p 8002:8002 -v $(pwd)/knowledgeBase:/app/knowledgeBase guixiaoxirag
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```bash
# ä½¿ç”¨ Gunicorn
pip install gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8002

# ä½¿ç”¨ Supervisor ç®¡ç†è¿›ç¨‹
# é…ç½® nginx åå‘ä»£ç†
# è®¾ç½® SSL è¯ä¹¦
```

## æ€§èƒ½ä¼˜åŒ–

### ç³»ç»Ÿä¼˜åŒ–
- å¯ç”¨ç¼“å­˜æœºåˆ¶
- è°ƒæ•´å¹¶å‘å‚æ•°
- ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
- ä½¿ç”¨è¿æ¥æ± 

### æŸ¥è¯¢ä¼˜åŒ–
- é€‰æ‹©åˆé€‚çš„æŸ¥è¯¢æ¨¡å¼
- è®¾ç½®åˆç†çš„ top_k å€¼
- ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢
- å¯ç”¨é‡æ’åº

### èµ„æºç›‘æ§
```python
# è·å–æ€§èƒ½æŒ‡æ ‡
response = requests.get("http://localhost:8002/api/v1/metrics")
print(response.json())

# è·å–ç¼“å­˜ç»Ÿè®¡
response = requests.get("http://localhost:8002/api/v1/cache/stats")
print(response.json())
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æœåŠ¡å¯åŠ¨å¤±è´¥**
   - æ£€æŸ¥ç«¯å£å ç”¨: `netstat -an | grep 8002`
   - æ£€æŸ¥ä¾èµ–å®‰è£…: `pip list`
   - æŸ¥çœ‹é”™è¯¯æ—¥å¿—: `tail -f logs/guixiaoxirag_service.log`

2. **æŸ¥è¯¢å“åº”æ…¢**
   - æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨
   - ä¼˜åŒ–æŸ¥è¯¢å‚æ•°
   - æ¸…ç†ç¼“å­˜

3. **æ–‡ä»¶ä¸Šä¼ å¤±è´¥**
   - æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
   - éªŒè¯æ–‡ä»¶æ ¼å¼æ”¯æŒ
   - æ£€æŸ¥ç£ç›˜ç©ºé—´

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/guixiaoxirag_service.log

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
curl http://localhost:8002/api/v1/logs?lines=100
```

## æµ‹è¯•

### è¿è¡Œæµ‹è¯•

```bash
# å®‰è£…æµ‹è¯•ä¾èµ–
pip install pytest pytest-asyncio

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_api_comprehensive.py -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=. tests/
```

### API æµ‹è¯•

```bash
# è¿è¡Œç»¼åˆAPIæµ‹è¯•
python tests/test_api_comprehensive.py

# ä½¿ç”¨curlæµ‹è¯•
curl -X GET http://localhost:8002/api/v1/health
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/new-feature`
3. æäº¤æ›´æ”¹: `git commit -am 'Add new feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/new-feature`
5. æäº¤ Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## æ›´æ–°æ—¥å¿—

### v2.0.0 (å½“å‰ç‰ˆæœ¬)
- é‡æ„APIæ¶æ„ï¼Œæä¾›æ›´æ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡
- å¢å¼ºæŸ¥è¯¢åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§æŸ¥è¯¢æ¨¡å¼
- å®Œå–„çŸ¥è¯†åº“ç®¡ç†åŠŸèƒ½
- æ–°å¢æ„å›¾è¯†åˆ«å’Œå®‰å…¨æ£€æŸ¥
- ä¼˜åŒ–æ€§èƒ½å’Œç¼“å­˜æœºåˆ¶
- å®Œå–„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

### v1.x.x
- åŸºç¡€åŠŸèƒ½å®ç°
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ

## ä¾èµ–é¡¹è¯´æ˜

### æ ¸å¿ƒä¾èµ–
- **FastAPI**: ç°ä»£ã€å¿«é€Ÿçš„Webæ¡†æ¶
- **Uvicorn**: ASGIæœåŠ¡å™¨
- **Pydantic**: æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç†
- **LightRAG**: è½»é‡çº§RAGæ¡†æ¶
- **NetworkX**: å›¾å½¢å’Œç½‘ç»œåˆ†æ
- **OpenAI**: LLMå’ŒEmbedding APIå®¢æˆ·ç«¯

### æ–‡æ¡£å¤„ç†
- **PyPDF2/pdfminer**: PDFæ–‡æ¡£å¤„ç†
- **python-docx**: Wordæ–‡æ¡£å¤„ç†
- **BeautifulSoup4**: HTML/XMLè§£æ
- **pandas**: æ•°æ®å¤„ç†å’Œåˆ†æ

### ç³»ç»Ÿå·¥å…·
- **psutil**: ç³»ç»Ÿå’Œè¿›ç¨‹ç›‘æ§
- **aiofiles**: å¼‚æ­¥æ–‡ä»¶æ“ä½œ
- **python-multipart**: æ–‡ä»¶ä¸Šä¼ æ”¯æŒ

## é…ç½®è¯¦è§£

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

```bash
# ===================
# åº”ç”¨åŸºç¡€é…ç½®
# ===================
APP_NAME="GuiXiaoXiRag FastAPI Service"
APP_VERSION="2.0.0"
HOST="0.0.0.0"
PORT=8002
DEBUG=false
WORKERS=1

# ===================
# LLMæœåŠ¡é…ç½®
# ===================
# LLM APIé…ç½®
OPENAI_API_BASE="http://localhost:8100/v1"
OPENAI_CHAT_API_KEY="your_api_key_here"
OPENAI_CHAT_MODEL="qwen14b"

# Embedding APIé…ç½®
OPENAI_EMBEDDING_API_BASE="http://localhost:8200/v1"
OPENAI_EMBEDDING_API_KEY="your_api_key_here"
OPENAI_EMBEDDING_MODEL="embedding_qwen"

# LLMå‚æ•°é…ç½®
LLM_ENABLED=true
LLM_PROVIDER="openai"
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=2048
LLM_TIMEOUT=30

# Embeddingå‚æ•°é…ç½®
EMBEDDING_ENABLED=true
EMBEDDING_PROVIDER="openai"
EMBEDDING_DIM=2560
EMBEDDING_TIMEOUT=30

# ===================
# çŸ¥è¯†åº“é…ç½®
# ===================
WORKING_DIR="./knowledgeBase/default"
MAX_TOKEN_SIZE=8192

# ===================
# æ–‡ä»¶å¤„ç†é…ç½®
# ===================
MAX_FILE_SIZE=52428800  # 50MB
UPLOAD_DIR="./uploads"
ALLOWED_FILE_TYPES=".txt,.pdf,.docx,.doc,.md,.json,.xml,.csv"

# ===================
# æ€§èƒ½é…ç½®
# ===================
ENABLE_CACHE=true
CACHE_TTL=3600
MAX_CONCURRENT_REQUESTS=100

# ===================
# å®‰å…¨é…ç½®
# ===================
CORS_ORIGINS="*"
CORS_METHODS="*"
CORS_HEADERS="*"

# ===================
# æ—¥å¿—é…ç½®
# ===================
LOG_LEVEL="INFO"
LOG_DIR="./logs"

# ===================
# Streamlité…ç½®ï¼ˆå¯é€‰ï¼‰
# ===================
STREAMLIT_HOST="0.0.0.0"
STREAMLIT_PORT=8501
STREAMLIT_API_URL="http://localhost:8002"
```

### é«˜çº§é…ç½®é€‰é¡¹

#### Azure OpenAI é…ç½®
```bash
# Azureç‰¹å®šé…ç½®
LLM_PROVIDER="azure"
AZURE_API_VERSION="2023-12-01-preview"
AZURE_DEPLOYMENT_NAME="gpt-35-turbo"
```

#### Ollama é…ç½®
```bash
# Ollamaæœ¬åœ°éƒ¨ç½²é…ç½®
LLM_PROVIDER="ollama"
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_CHAT_MODEL="llama2"
OLLAMA_EMBEDDING_MODEL="nomic-embed-text"
```

#### Rerank é…ç½®
```bash
# é‡æ’åºæœåŠ¡é…ç½®
RERANK_ENABLED=false
RERANK_PROVIDER="openai"
RERANK_MODEL="rerank-multilingual-v3.0"
RERANK_TOP_K=10
```

## è¯¦ç»†ä½¿ç”¨ç¤ºä¾‹

### 1. å®Œæ•´çš„æŸ¥è¯¢æµç¨‹

```python
import requests
import json

class GuiXiaoXiRagClient:
    def __init__(self, base_url="http://localhost:8002"):
        self.base_url = base_url
        self.api_base = f"{base_url}/api/v1"
        self.session = requests.Session()

    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        response = self.session.get(f"{self.api_base}/health")
        return response.json()

    def query(self, query_text, mode="hybrid", **kwargs):
        """æ™ºèƒ½æŸ¥è¯¢"""
        data = {
            "query": query_text,
            "mode": mode,
            **kwargs
        }
        response = self.session.post(f"{self.api_base}/query", json=data)
        return response.json()

    def insert_text(self, text, knowledge_base=None, **kwargs):
        """æ’å…¥æ–‡æœ¬"""
        data = {
            "text": text,
            "knowledge_base": knowledge_base,
            **kwargs
        }
        response = self.session.post(f"{self.api_base}/insert/text", json=data)
        return response.json()

    def upload_file(self, file_path, knowledge_base=None, **kwargs):
        """ä¸Šä¼ æ–‡ä»¶"""
        with open(file_path, "rb") as f:
            files = {"file": f}
            data = {"knowledge_base": knowledge_base, **kwargs}
            response = self.session.post(
                f"{self.api_base}/insert/file",
                files=files,
                data=data
            )
        return response.json()

    def create_knowledge_base(self, name, description="", **config):
        """åˆ›å»ºçŸ¥è¯†åº“"""
        data = {
            "name": name,
            "description": description,
            "config": config
        }
        response = self.session.post(f"{self.api_base}/knowledge-bases", json=data)
        return response.json()

    def switch_knowledge_base(self, name):
        """åˆ‡æ¢çŸ¥è¯†åº“"""
        data = {"name": name}
        response = self.session.post(f"{self.api_base}/knowledge-bases/switch", json=data)
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = GuiXiaoXiRagClient()

# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
health = client.health_check()
print(f"æœåŠ¡çŠ¶æ€: {health}")

# 2. åˆ›å»ºçŸ¥è¯†åº“
kb_result = client.create_knowledge_base(
    name="ai_tutorial",
    description="äººå·¥æ™ºèƒ½æ•™ç¨‹çŸ¥è¯†åº“",
    chunk_size=1024,
    chunk_overlap=50
)
print(f"çŸ¥è¯†åº“åˆ›å»º: {kb_result}")

# 3. åˆ‡æ¢åˆ°æ–°çŸ¥è¯†åº“
switch_result = client.switch_knowledge_base("ai_tutorial")
print(f"çŸ¥è¯†åº“åˆ‡æ¢: {switch_result}")

# 4. æ’å…¥æ–‡æ¡£å†…å®¹
texts = [
    "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚",
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
    "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚"
]

for i, text in enumerate(texts):
    result = client.insert_text(
        text=text,
        doc_id=f"ai_doc_{i+1}",
        knowledge_base="ai_tutorial"
    )
    print(f"æ–‡æ¡£æ’å…¥ {i+1}: {result.get('success')}")

# 5. æ‰§è¡ŒæŸ¥è¯¢
queries = [
    "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å¦‚ä½•å¼€å§‹å­¦ä¹ AIï¼Ÿ"
]

for query in queries:
    result = client.query(
        query_text=query,
        mode="hybrid",
        top_k=5,
        knowledge_base="ai_tutorial"
    )
    print(f"\næŸ¥è¯¢: {query}")
    if result.get('success'):
        answer = result.get('data', {}).get('answer', '')
        print(f"å›ç­”: {answer[:200]}...")
    else:
        print(f"æŸ¥è¯¢å¤±è´¥: {result.get('message')}")
```

### 2. æ‰¹é‡æ–‡æ¡£å¤„ç†

```python
import os
import glob

def batch_upload_documents(client, directory_path, knowledge_base):
    """æ‰¹é‡ä¸Šä¼ ç›®å½•ä¸­çš„æ–‡æ¡£"""
    supported_extensions = ['.txt', '.pdf', '.docx', '.md', '.json']

    results = []
    for ext in supported_extensions:
        files = glob.glob(os.path.join(directory_path, f"*{ext}"))

        for file_path in files:
            try:
                result = client.upload_file(
                    file_path=file_path,
                    knowledge_base=knowledge_base,
                    extract_metadata=True
                )
                results.append({
                    'file': os.path.basename(file_path),
                    'success': result.get('success'),
                    'message': result.get('message')
                })
                print(f"ä¸Šä¼  {os.path.basename(file_path)}: {result.get('success')}")
            except Exception as e:
                results.append({
                    'file': os.path.basename(file_path),
                    'success': False,
                    'message': str(e)
                })
                print(f"ä¸Šä¼ å¤±è´¥ {os.path.basename(file_path)}: {e}")

    return results

# ä½¿ç”¨ç¤ºä¾‹
upload_results = batch_upload_documents(
    client=client,
    directory_path="./documents",
    knowledge_base="ai_tutorial"
)

# ç»Ÿè®¡ç»“æœ
successful = sum(1 for r in upload_results if r['success'])
total = len(upload_results)
print(f"\næ‰¹é‡ä¸Šä¼ å®Œæˆ: {successful}/{total} æˆåŠŸ")
```

### 3. çŸ¥è¯†å›¾è°±æ“ä½œ

```python
def explore_knowledge_graph(client, node_label="äººå·¥æ™ºèƒ½"):
    """æ¢ç´¢çŸ¥è¯†å›¾è°±"""

    # è·å–å›¾è°±æ•°æ®
    graph_data = client.session.post(f"{client.api_base}/knowledge-graph", json={
        "node_label": node_label,
        "max_depth": 3,
        "max_nodes": 100,
        "include_metadata": True
    }).json()

    if graph_data.get('success'):
        data = graph_data.get('data', {})
        print(f"èŠ‚ç‚¹æ•°é‡: {data.get('node_count', 0)}")
        print(f"è¾¹æ•°é‡: {data.get('edge_count', 0)}")

        # æ˜¾ç¤ºéƒ¨åˆ†èŠ‚ç‚¹ä¿¡æ¯
        nodes = data.get('nodes', [])[:5]
        for node in nodes:
            print(f"èŠ‚ç‚¹: {node.get('label')} (ID: {node.get('id')})")

    # è·å–å›¾è°±ç»Ÿè®¡
    stats = client.session.get(f"{client.api_base}/knowledge-graph/stats").json()
    if stats.get('success'):
        stats_data = stats.get('data', {})
        print(f"\nå›¾è°±ç»Ÿè®¡:")
        print(f"  æ€»èŠ‚ç‚¹æ•°: {stats_data.get('node_count', 0)}")
        print(f"  æ€»è¾¹æ•°: {stats_data.get('edge_count', 0)}")
        print(f"  å›¾è°±å¯†åº¦: {stats_data.get('density', 0):.4f}")

    # ç”Ÿæˆå¯è§†åŒ–
    viz_result = client.session.post(f"{client.api_base}/knowledge-graph/visualize", json={
        "max_nodes": 50,
        "layout": "spring",
        "node_size_field": "degree"
    }).json()

    if viz_result.get('success'):
        viz_data = viz_result.get('data', {})
        html_path = viz_data.get('html_file_path')
        print(f"å¯è§†åŒ–æ–‡ä»¶å·²ç”Ÿæˆ: {html_path}")

# ä½¿ç”¨ç¤ºä¾‹
explore_knowledge_graph(client)
```

## ç›‘æ§å’Œç»´æŠ¤

### ç³»ç»Ÿç›‘æ§è„šæœ¬

```python
import time
import psutil
import requests
from datetime import datetime

class SystemMonitor:
    def __init__(self, api_base="http://localhost:8002/api/v1"):
        self.api_base = api_base
        self.session = requests.Session()

    def check_system_health(self):
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        try:
            # APIå¥åº·æ£€æŸ¥
            health_response = self.session.get(f"{self.api_base}/health", timeout=5)
            api_healthy = health_response.status_code == 200

            # ç³»ç»Ÿèµ„æºæ£€æŸ¥
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')

            # è·å–APIæŒ‡æ ‡
            metrics_response = self.session.get(f"{self.api_base}/metrics")
            api_metrics = metrics_response.json() if metrics_response.status_code == 200 else {}

            status = {
                'timestamp': datetime.now().isoformat(),
                'api_healthy': api_healthy,
                'system': {
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory.percent,
                    'memory_available_gb': memory.available / (1024**3),
                    'disk_percent': disk.percent,
                    'disk_free_gb': disk.free / (1024**3)
                },
                'api_metrics': api_metrics.get('data', {}) if api_metrics else {}
            }

            return status

        except Exception as e:
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'api_healthy': False
            }

    def monitor_loop(self, interval=60):
        """ç›‘æ§å¾ªç¯"""
        print("å¼€å§‹ç³»ç»Ÿç›‘æ§...")

        while True:
            status = self.check_system_health()

            print(f"\n[{status['timestamp']}]")
            print(f"APIçŠ¶æ€: {'å¥åº·' if status.get('api_healthy') else 'å¼‚å¸¸'}")

            if 'system' in status:
                sys_info = status['system']
                print(f"CPUä½¿ç”¨ç‡: {sys_info['cpu_percent']:.1f}%")
                print(f"å†…å­˜ä½¿ç”¨ç‡: {sys_info['memory_percent']:.1f}%")
                print(f"ç£ç›˜ä½¿ç”¨ç‡: {sys_info['disk_percent']:.1f}%")

            if 'api_metrics' in status and status['api_metrics']:
                metrics = status['api_metrics']
                print(f"è¯·æ±‚æ€»æ•°: {metrics.get('request_count', 0)}")
                print(f"é”™è¯¯ç‡: {metrics.get('error_rate', 0):.2%}")
                print(f"å¹³å‡å“åº”æ—¶é—´: {metrics.get('avg_response_time', 0):.2f}ms")

            # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
            if 'system' in status:
                sys_info = status['system']
                if sys_info['cpu_percent'] > 80:
                    print("âš ï¸  CPUä½¿ç”¨ç‡è¿‡é«˜!")
                if sys_info['memory_percent'] > 85:
                    print("âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜!")
                if sys_info['disk_percent'] > 90:
                    print("âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³!")

            if not status.get('api_healthy'):
                print("ğŸš¨ APIæœåŠ¡å¼‚å¸¸!")

            time.sleep(interval)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    monitor = SystemMonitor()

    # å•æ¬¡æ£€æŸ¥
    status = monitor.check_system_health()
    print(json.dumps(status, indent=2, ensure_ascii=False))

    # æŒç»­ç›‘æ§ï¼ˆå¯é€‰ï¼‰
    # monitor.monitor_loop(interval=30)
```

### ç¼“å­˜ç®¡ç†è„šæœ¬

```python
def manage_cache(client):
    """ç¼“å­˜ç®¡ç†"""

    # è·å–ç¼“å­˜ç»Ÿè®¡
    cache_stats = client.session.get(f"{client.api_base}/cache/stats").json()

    if cache_stats.get('success'):
        stats_data = cache_stats.get('data', {})
        total_memory = stats_data.get('total_memory_mb', 0)

        print(f"ç¼“å­˜æ€»å†…å­˜ä½¿ç”¨: {total_memory:.2f} MB")

        caches = stats_data.get('caches', {})
        for cache_type, cache_info in caches.items():
            size_mb = cache_info.get('size_mb', 0)
            hit_rate = cache_info.get('hit_rate', 0)
            print(f"  {cache_type}: {size_mb:.2f} MB, å‘½ä¸­ç‡: {hit_rate:.2%}")

        # å¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œæ¸…ç†ç¼“å­˜
        if total_memory > 1000:  # è¶…è¿‡1GB
            print("å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œå¼€å§‹æ¸…ç†ç¼“å­˜...")

            # æ¸…ç†ç‰¹å®šç±»å‹ç¼“å­˜
            for cache_type in ['llm', 'vector']:
                clear_result = client.session.delete(
                    f"{client.api_base}/cache/clear/{cache_type}"
                ).json()

                if clear_result.get('success'):
                    freed_mb = clear_result.get('data', {}).get('freed_memory_mb', 0)
                    print(f"æ¸…ç† {cache_type} ç¼“å­˜ï¼Œé‡Šæ”¾ {freed_mb:.2f} MB")

# ä½¿ç”¨ç¤ºä¾‹
manage_cache(client)
```